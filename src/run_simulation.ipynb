{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import queue\n",
    "import shutil \n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "from enum import Enum\n",
    "from datetime import datetime\n",
    "\n",
    "import carla\n",
    "import numpy as np\n",
    "import urdf_parser_py.urdf as urdf\n",
    "from scipy.spatial.transform import Rotation   \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import open3d as o3d\n",
    "import cv2\n",
    "os.environ['PYGAME_HIDE_SUPPORT_PROMPT'] = \"hide\"\n",
    "import pygame\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the CARLA Python API path\n",
    "CURRENT_WORKING_DIR = os.getcwd()\n",
    "CARLA_PYTHON_API_PATH = os.path.join(CURRENT_WORKING_DIR, \"CARLASimulator\", \"PythonAPI\", \"carla\")\n",
    "if CARLA_PYTHON_API_PATH not in sys.path:\n",
    "    sys.path.append(CARLA_PYTHON_API_PATH)\n",
    "\n",
    "# Import the BasicAgent\n",
    "try:\n",
    "    from agents.navigation.basic_agent import BasicAgent\n",
    "    from agents.navigation.behavior_agent import BehaviorAgent\n",
    "except ImportError as error:\n",
    "    raise ImportError(f\"FATAL ERROR: Unable to import CARLA autonomous driving agent BasicAgent due to missing PythonAPI. The API is included in the simulator installation package (not included with 'import carla'). Setup the CARLA simulator repository and add the correct PythonAPI path above. ({error})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Command-line arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class URDFParser:\n",
    "    def __init__(self, urdf_file):\n",
    "        self.urdf_file = urdf_file\n",
    "        self.robot = urdf.URDF.from_xml_file(urdf_file)\n",
    "        self.root = self.robot.get_root()\n",
    "\n",
    "    def compute_chain_transform(self, chain):\n",
    "        transform = np.eye(4)\n",
    "        \n",
    "        for joint in chain:\n",
    "            if joint not in self.robot.joint_map:\n",
    "                continue\n",
    "            \n",
    "            joint_info = self.robot.joint_map[joint]\n",
    "            rpy = joint_info.origin.rpy\n",
    "            xyz = joint_info.origin.xyz\n",
    "            rotation = Rotation.from_euler('xyz', rpy).as_matrix()\n",
    "            translation = np.array(xyz)\n",
    "            T = self.build_transform_matrix(rotation, translation)\n",
    "            transform = np.dot(transform, T)\n",
    "        \n",
    "        return transform\n",
    "\n",
    "    def get_T_from_to(self, start_frame, end_frame):\n",
    "        chain_1 = self.robot.get_chain(self.root, start_frame)\n",
    "        chain_2 = self.robot.get_chain(self.root, end_frame)\n",
    "        T1 = self.compute_chain_transform(chain_1)\n",
    "        T2 = self.compute_chain_transform(chain_2)\n",
    "        return np.dot(np.linalg.inv(T1), T2)\n",
    "    \n",
    "    def build_transform_matrix(self, rotation, translation):\n",
    "        m = np.eye(4)\n",
    "        m[:3, :3] = rotation\n",
    "        m[:3, 3] = translation\n",
    "        return m\n",
    "\n",
    "# Parse the arguments if running from command line or \n",
    "# use default values if running from Jupyter Notebook\n",
    "if 'ipykernel_launcher.py' in sys.argv[0]: \n",
    "    args = argparse.Namespace(\n",
    "        ego_vehicle_extrinsics='/home/leppsalu/Desktop/Github/voxel-visibility-multithreaded/CARLA-vehicle-simulation/src/config/carla_extrinsics.urdf',\n",
    "        ego_vehicle_intrinsics='/home/leppsalu/Desktop/Github/voxel-visibility-multithreaded/CARLA-vehicle-simulation/src/config/carla_intrinsics.json',\n",
    "        episode_config='/home/leppsalu/Desktop/Github/voxel-visibility-multithreaded/CARLA-vehicle-simulation/src/config/town03.path.json',\n",
    "        output_dir='/media/leppsalu/SSD_Storage/generated_data_town03_sample',\n",
    "        skip_validation=True,\n",
    "        toggle_off_buildings=False\n",
    "    )\n",
    "else:\n",
    "    # Create the parser\n",
    "    parser = argparse.ArgumentParser(description='Run simulation postprocessing.')\n",
    "    # Add arguments\n",
    "    parser.add_argument('--ego_vehicle_extrinsics', type=str, required=False, default='/home/leppsalu/Desktop/Github/CARLA-vehicle-simulation/src/config/carla_extrinsics.urdf',\n",
    "                        help='Path to the ego vehicle extrinsics file')\n",
    "    parser.add_argument('--ego_vehicle_intrinsics', type=str, required=False, default='/home/leppsalu/Desktop/Github/CARLA-vehicle-simulation/src/config/carla_intrinsics.json',\n",
    "                        help='Path to the ego vehicle intrinsics file')\n",
    "    parser.add_argument('--episode_config', type=str, required=False, default='/home/leppsalu/Desktop/Github/CARLA-vehicle-simulation/src/config/town02.path.json',\n",
    "                        help='Path to the episode specific configuration file')\n",
    "    parser.add_argument('--output_dir', type=str, required=False, default='/home/leppsalu/Desktop/Github/CARLA-vehicle-simulation/src/generated_data',\n",
    "                        help='Path to the output directory')\n",
    "    parser.add_argument('--skip_validation', action='store_true', help='Skip validation run for current episode config and start full simulation immediately.')\n",
    "    parser.add_argument('--toggle_off_buildings', action='store_true', help='Toggle off buildings in the simulation.')\n",
    "    # Parse the arguments\n",
    "    args = parser.parse_args()\n",
    "\n",
    "EGO_VEHICLE_EXTRINSICS = args.ego_vehicle_extrinsics\n",
    "ego_vehicle_extrinsics = URDFParser(EGO_VEHICLE_EXTRINSICS)\n",
    "\n",
    "EGO_VEHICLE_INTRINSICS = args.ego_vehicle_intrinsics\n",
    "ego_vehicle_intrinsics = dict()\n",
    "with open(EGO_VEHICLE_INTRINSICS) as intrinsics_file:\n",
    "    ego_vehicle_intrinsics = json.load(intrinsics_file)\n",
    "\n",
    "EPISODE_CONFIG_PATH = args.episode_config\n",
    "episode_config_json = dict()\n",
    "with open(EPISODE_CONFIG_PATH) as path_file:\n",
    "    episode_config_json = json.load(path_file)\n",
    "episode_map = episode_config_json[\"map\"]\n",
    "episode_ego_vehicle_path = episode_config_json[\"route\"]\n",
    "\n",
    "SIMULATION_DATA_OUTPUT_PATH = args.output_dir\n",
    "\n",
    "SKIP_VALIDATION = args.skip_validation\n",
    "\n",
    "TOGGLE_OFF_BUILDINGS = args.toggle_off_buildings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to CARLA server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(100)\n",
    "world = client.get_world()\n",
    "map = world.get_map()\n",
    "\n",
    "blueprint_library = world.get_blueprint_library()\n",
    "spawn_points = world.get_map().get_spawn_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_world():\n",
    "    global world, map, blueprint_library, spawn_points, traffic_manager\n",
    "    world = client.reload_world()\n",
    "    map = world.get_map()\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    spawn_points = map.get_spawn_points()\n",
    "    traffic_manager = client.get_trafficmanager()\n",
    "\n",
    "def load_world(map_name=\"Town01\", timeout=10.0):\n",
    "    global world, map, blueprint_library, spawn_points, traffic_manager\n",
    "    client.set_timeout(timeout)\n",
    "    world = client.load_world(map_name)\n",
    "    map = world.get_map()\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    spawn_points = map.get_spawn_points()\n",
    "    traffic_manager = client.get_trafficmanager()\n",
    "\n",
    "load_world(map_name=episode_map)\n",
    "reload_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarlaSyncMode(object):\n",
    "    \"\"\"\n",
    "        with CarlaSyncMode(world, sensors) as sync_mode:\n",
    "            while True:\n",
    "                data = sync_mode.tick(timeout=1.0)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, world, sensors, **kwargs):\n",
    "        self.world = world\n",
    "        self.sensors = sensors\n",
    "        self.frame = None\n",
    "        self.delta_seconds = 1.0 / kwargs.get('fps', 10)\n",
    "        self._queues = []\n",
    "        self._settings = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        self._settings = self.world.get_settings()\n",
    "        self.frame = self.world.apply_settings(carla.WorldSettings(\n",
    "            no_rendering_mode=False,\n",
    "            synchronous_mode=True,\n",
    "            fixed_delta_seconds=self.delta_seconds,\n",
    "            ))\n",
    "\n",
    "        def make_queue(register_event):\n",
    "            q = queue.Queue()\n",
    "            register_event(q.put)\n",
    "            self._queues.append(q)\n",
    "\n",
    "        make_queue(self.world.on_tick)\n",
    "        for sensor in self.sensors:\n",
    "            make_queue(sensor.listen)\n",
    "        return self\n",
    "\n",
    "    def tick(self, timeout=300):\n",
    "        self.frame = self.world.tick()\n",
    "        data = [self._retrieve_data(q, timeout) for q in self._queues]\n",
    "        assert all(x.frame == self.frame for x in data)\n",
    "        return data\n",
    "\n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        self.world.apply_settings(self._settings)\n",
    "\n",
    "    def _retrieve_data(self, sensor_queue, timeout):\n",
    "        while True:\n",
    "            data = sensor_queue.get(timeout=timeout)\n",
    "            if data.frame == self.frame:\n",
    "                return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CARLA transformation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_to_transform(matrix):\n",
    "    # Ensure matrix is a NumPy array\n",
    "    if not isinstance(matrix, np.ndarray):\n",
    "        matrix = np.array(matrix)\n",
    "\n",
    "    location = carla.Location(x=matrix[0, 3], y=(-matrix[1, 3]), z=matrix[2, 3])\n",
    "    roll, pitch, yaw = Rotation.from_matrix(matrix[:3, :3]).as_euler('xyz', degrees=True)\n",
    "    rotation = carla.Rotation(pitch=(-pitch), yaw=(-yaw), roll=roll)\n",
    "\n",
    "    # location = carla.Location(x=matrix[0, 3], y=(matrix[1, 3]), z=matrix[2, 3])\n",
    "    # roll, pitch, yaw = Rotation.from_matrix(matrix[:3, :3]).as_euler('xyz', degrees=True)\n",
    "    # rotation = carla.Rotation(pitch=(pitch), yaw=(yaw), roll=roll)\n",
    "    \n",
    "    # Create and return carla.Transform\n",
    "    return carla.Transform(location, rotation)\n",
    "\n",
    "\n",
    "def rotation_matrix(axis, angle):\n",
    "    \"\"\"\n",
    "    Create a rotation matrix for a given axis and angle.\n",
    "    \"\"\"\n",
    "    if axis == 'x':\n",
    "        return np.array([\n",
    "            [1, 0, 0, 0],\n",
    "            [0, np.cos(angle), -np.sin(angle), 0],\n",
    "            [0, np.sin(angle), np.cos(angle), 0],\n",
    "            [0, 0, 0, 1]\n",
    "        ])\n",
    "    elif axis == 'y':\n",
    "        return np.array([\n",
    "            [np.cos(angle), 0, np.sin(angle), 0],\n",
    "            [0, 1, 0, 0],\n",
    "            [-np.sin(angle), 0, np.cos(angle), 0],\n",
    "            [0, 0, 0, 1]\n",
    "        ])\n",
    "    elif axis == 'z':\n",
    "        return np.array([\n",
    "            [np.cos(angle), -np.sin(angle), 0, 0],\n",
    "            [np.sin(angle), np.cos(angle), 0, 0],\n",
    "            [0, 0, 1, 0],\n",
    "            [0, 0, 0, 1]\n",
    "        ])\n",
    "\n",
    "def reflection_matrix():\n",
    "    \"\"\"\n",
    "    Create a reflection matrix to flip the Y-axis.\n",
    "    \"\"\"\n",
    "    return np.array([\n",
    "        [-1, 0, 0, 0],\n",
    "        [0, 1, 0, 0],\n",
    "        [0, 0, 1, 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ])\n",
    "\n",
    "\n",
    "def transform_to_carla(sensor_type, transformation):\n",
    "    \"\"\"\n",
    "    Convert sensor transformation to CARLA format.\n",
    "    \"\"\"\n",
    "    sensor_type = sensor_type.lower().strip()\n",
    "    if sensor_type in ['camera', 'sensor.camera', 'sensor.camera.rgb', 'sensor.camera.semantic_segmentation', 'sensor.camera.instance_segmentation', 'sensor.camera.depth']:\n",
    "        rotation1 = rotation_matrix('z', np.pi / 2)\n",
    "        rotation2 = rotation_matrix('y', -np.pi / 2)\n",
    "        rotation = np.dot(rotation1, rotation2)\n",
    "    elif sensor_type in ['lidar', 'sensor.lidar', 'sensor.lidar.ray_cast', 'sensor.lidar.ray_cast_semantic']:\n",
    "        rotation = rotation_matrix('z', np.pi / 2)\n",
    "        # rotation2 = rotation_matrix('y', np.pi)\n",
    "        # rotation = np.dot(rotation1, rotation2)\n",
    "    elif sensor_type in ['radar', 'sensor.other.radar']:\n",
    "        rotation = np.eye(4)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown sensor type: {sensor_type}\")\n",
    "    tf = np.dot(transformation, rotation)\n",
    "    return tf\n",
    "\n",
    "def transform_from_carla(sensor_type):\n",
    "    \"\"\"\n",
    "    Convert sensor transformation from CARLA format.\n",
    "    \"\"\"\n",
    "    sensor_type = sensor_type.lower().strip()\n",
    "    original_tf = transform_to_carla(sensor_type, np.eye(4))\n",
    "    inverse_tf = np.linalg.inv(original_tf)\n",
    "    \n",
    "    tf = inverse_tf\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run path validation in CARLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agent_path(coordinates):\n",
    "    path = []\n",
    "    for x, y, z in coordinates:\n",
    "        location = carla.Location(x=x, y=y, z=z)\n",
    "        waypoint = map.get_waypoint(\n",
    "            location,\n",
    "            project_to_road=True, \n",
    "            lane_type=(carla.LaneType.Driving))\n",
    "        waypoint_location = waypoint.transform.location\n",
    "        path.append(waypoint_location)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_path():\n",
    "    reload_world()\n",
    "\n",
    "    cv2.namedWindow(\"Press Q to stop simulation\")\n",
    "    cv2.imshow(\"Press Q to stop simulation\", np.zeros((1,1)))\n",
    "\n",
    "    blueprint_name = \"vehicle.kawasaki.ninja\"\n",
    "    blueprint = blueprint_library.find(blueprint_name)\n",
    "    transform = spawn_points[0]\n",
    "    validation_vehicle = world.spawn_actor(blueprint, transform)\n",
    "\n",
    "    blueprint = blueprint_library.find(\"sensor.camera.rgb\")\n",
    "    blueprint.set_attribute('image_size_x', str(720))\n",
    "    blueprint.set_attribute('image_size_y', str(480))\n",
    "\n",
    "    transform_matrix = carla.Transform(carla.Location(x=1.7, y=0.0, z=1.5), carla.Rotation(roll=0, pitch=0, yaw=0)).get_matrix()\n",
    "    transform = matrix_to_transform(transform_matrix)\n",
    "    sensor = world.spawn_actor(blueprint, transform, attach_to=validation_vehicle)\n",
    "    validation_vehicle_control_agent = BasicAgent(validation_vehicle)#, target_speed=15)\n",
    "    validation_vehicle_control_agent.ignore_traffic_lights()\n",
    "    validation_vehicle_control_agent.ignore_stop_signs()\n",
    "    agent_path = get_agent_path(episode_ego_vehicle_path)\n",
    "    validation_vehicle_control_agent.set_destination(agent_path.pop(0))\n",
    "\n",
    "    agent_path_completed = False\n",
    "    try:\n",
    "        with CarlaSyncMode(world, [sensor], fps=10) as sync_mode:\n",
    "            print(\"Driving to the start of the path...\")\n",
    "            while validation_vehicle_control_agent.done() is False:\n",
    "                if (cv2.waitKey(1) == ord('q')):\n",
    "                    break\n",
    "                simulated_results = sync_mode.tick()[1:]\n",
    "                cam_sensor = simulated_results[0]\n",
    "                cam_sensor_image =  np.reshape(np.copy(cam_sensor.raw_data), (cam_sensor.height, cam_sensor.width, 4))\n",
    "                cv2.imshow(\"CAM_FRONT\", cam_sensor_image)\n",
    "\n",
    "                validation_vehicle.apply_control(validation_vehicle_control_agent.run_step())\n",
    "            print(\"Arrived at the start of the path!\")\n",
    "\n",
    "            print(\"Driving on path...\")\n",
    "            actual_path = []\n",
    "            while True:\n",
    "                if (cv2.waitKey(1) == ord('q')):\n",
    "                    break\n",
    "\n",
    "                simulated_results = sync_mode.tick()[1:]\n",
    "                cam_sensor = simulated_results[0]\n",
    "                cam_sensor_image =  np.reshape(np.copy(cam_sensor.raw_data), (cam_sensor.height, cam_sensor.width, 4))\n",
    "                cv2.imshow(\"CAM_FRONT\", cam_sensor_image)\n",
    "\n",
    "                location = validation_vehicle.get_location()\n",
    "                actual_path.append((location.x, location.y, location.z))\n",
    "                \n",
    "                if validation_vehicle_control_agent.done():\n",
    "                    print(f\"{datetime.now()} Checkpoint reached. Validation vehicle has reached {len(episode_ego_vehicle_path) - len(agent_path)}/{len(episode_ego_vehicle_path)} planned path points.\")\n",
    "                    if (agent_path == []):\n",
    "                        agent_path_completed = True\n",
    "                        break\n",
    "                    validation_vehicle_control_agent.set_destination(agent_path.pop(0))\n",
    "                validation_vehicle.apply_control(validation_vehicle_control_agent.run_step())\n",
    "            print(\"Drive finished!\")\n",
    "    except RuntimeError as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        cv2.destroyAllWindows()\n",
    "        validation_vehicle.destroy()\n",
    "\n",
    "    assert agent_path_completed, \"Validation failed. The vehicle could not complete the planned path.\"\n",
    "    return episode_ego_vehicle_path, actual_path\n",
    "\n",
    "\n",
    "validation_results = dict()\n",
    "if not SKIP_VALIDATION:\n",
    "    print(\"Validating the episode path...\")\n",
    "    episode_ego_vehicle_path, actual_path = validate_path()\n",
    "    validation_results[\"planned_path\"] = episode_ego_vehicle_path\n",
    "    validation_results[\"actual_path\"] = actual_path\n",
    "    print(\"Validation path successfully completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_path(coords, min_distance):\n",
    "    def distance(point1, point2):\n",
    "        return math.sqrt((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)\n",
    "    filtered_coords = []\n",
    "    for i in range(len(coords)):\n",
    "        if (i == 0) or (i == (len(coords)-1)) or distance(filtered_coords[-1], coords[i]) >= min_distance:\n",
    "            filtered_coords.append(coords[i])\n",
    "    return filtered_coords\n",
    "\n",
    "def visualize_paths(planned_path, actual_path):\n",
    "    # Initialize Pygame\n",
    "    pygame.init()\n",
    "\n",
    "    # Constants\n",
    "    WIDTH, HEIGHT = 800, 600\n",
    "    BACKGROUND_COLOR = (255, 255, 255)\n",
    "    NODE_COLOR = (0, 0, 255)\n",
    "    EDGE_COLOR = (0, 0, 0)  # For the planned coordinates\n",
    "    PLANNED_NODE_COLOR = (0, 255, 0)\n",
    "    PLANNED_EDGE_COLOR = (0, 200, 0)\n",
    "    NODE_RADIUS = 5\n",
    "    ARROW_SIZE = 10\n",
    "    FONT_COLOR = (0, 0, 0)\n",
    "\n",
    "    # Create the screen\n",
    "    screen = pygame.display.set_mode((WIDTH, HEIGHT))\n",
    "    pygame.display.set_caption(\"Validation path summary\")\n",
    "\n",
    "    # Zoom and pan variables\n",
    "    scale = 1.0\n",
    "    offset_x, offset_y = 0, 0\n",
    "    zoom_factor = 1.1\n",
    "    dragging = False\n",
    "    last_mouse_pos = (0, 0)\n",
    "\n",
    "    # Checkbox states\n",
    "    show_actual_path = True\n",
    "    show_planned_path = True\n",
    "\n",
    "    # Slider values\n",
    "    actual_path_distance_filter = 10.0\n",
    "    planned_path_distance_filter = 10.0\n",
    "\n",
    "    def draw_arrow(surface, start, end, color):\n",
    "        pygame.draw.line(surface, color, start, end, 2)\n",
    "        \n",
    "        angle = math.atan2(end[1] - start[1], end[0] - start[0])\n",
    "        left_angle = angle + math.pi / 6\n",
    "        right_angle = angle - math.pi / 6\n",
    "\n",
    "        left_point = (end[0] - ARROW_SIZE * math.cos(left_angle),\n",
    "                      end[1] - ARROW_SIZE * math.sin(left_angle))\n",
    "        right_point = (end[0] - ARROW_SIZE * math.cos(right_angle),\n",
    "                       end[1] - ARROW_SIZE * math.sin(right_angle))\n",
    "\n",
    "        pygame.draw.polygon(surface, color, [end, left_point, right_point])\n",
    "\n",
    "    def draw_nodes_and_edges(coords, node_color, edge_color):\n",
    "        for i, (x, y, z) in enumerate(coords):\n",
    "            scaled_x = (x + offset_x) * scale\n",
    "            scaled_y = (y + offset_y) * scale\n",
    "            \n",
    "            pygame.draw.circle(screen, node_color, (int(scaled_x), int(scaled_y)), NODE_RADIUS)\n",
    "            \n",
    "            font = pygame.font.Font(None, 24)\n",
    "            text_surface = font.render(str(i), True, FONT_COLOR)\n",
    "            screen.blit(text_surface, (scaled_x + 10, scaled_y - 10))\n",
    "            \n",
    "            if i < len(coords) - 1:\n",
    "                next_x, next_y, _ = coords[i + 1]\n",
    "                next_scaled_x = (next_x + offset_x) * scale\n",
    "                next_scaled_y = (next_y + offset_y) * scale\n",
    "                draw_arrow(screen, (int(scaled_x), int(scaled_y)), (int(next_scaled_x), int(next_scaled_y)), edge_color)\n",
    "\n",
    "    def draw_checkbox(x, y, label, checked):\n",
    "        pygame.draw.rect(screen, (0, 0, 0), (x, y, 20, 20), 2)\n",
    "        if checked:\n",
    "            pygame.draw.rect(screen, (0, 255, 0), (x + 2, y + 2, 16, 16))\n",
    "\n",
    "        font = pygame.font.Font(None, 24)\n",
    "        text_surface = font.render(label, True, FONT_COLOR)\n",
    "        screen.blit(text_surface, (x + 30, y))\n",
    "\n",
    "    def draw_slider(x, y, value):\n",
    "        pygame.draw.rect(screen, (200, 200, 200), (x, y, 200, 20))  # Slider background\n",
    "        pygame.draw.rect(screen, (100, 100, 100), (x + int(value), y, 10, 20))  # Slider handle\n",
    "\n",
    "    # Main loop\n",
    "    clock = pygame.time.Clock()\n",
    "    running = True\n",
    "    \n",
    "    while running:\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                running = False\n",
    "            elif event.type == pygame.KEYDOWN:\n",
    "                if event.key == pygame.K_ESCAPE:\n",
    "                    running = False\n",
    "            \n",
    "            # Zoom with mouse scroll wheel\n",
    "            elif event.type == pygame.MOUSEBUTTONDOWN:\n",
    "                if event.button == 4:  # Scroll up\n",
    "                    scale *= zoom_factor\n",
    "                elif event.button == 5:  # Scroll down\n",
    "                    scale /= zoom_factor\n",
    "                elif event.button == 1:  # Left mouse button\n",
    "                    dragging = True\n",
    "                    last_mouse_pos = pygame.mouse.get_pos()\n",
    "\n",
    "            elif event.type == pygame.MOUSEBUTTONUP:\n",
    "                if event.button == 1:  # Left mouse button\n",
    "                    dragging = False\n",
    "                # Click on checkboxes\n",
    "                mouse_pos = pygame.mouse.get_pos()\n",
    "                if 10 <= mouse_pos[0] <= 30 and 10 <= mouse_pos[1] <= 30:\n",
    "                    show_actual_path = not show_actual_path\n",
    "                if 10 <= mouse_pos[0] <= 30 and 90 <= mouse_pos[1] <= 110:\n",
    "                    show_planned_path = not show_planned_path\n",
    "\n",
    "            elif event.type == pygame.MOUSEMOTION:\n",
    "                mouse_on_slider = False\n",
    "                if dragging:\n",
    "                    mouse_x, mouse_y = pygame.mouse.get_pos()\n",
    "                    if (10 <= mouse_x <= 210) and (40 <= mouse_y <= 80):  # Adjust value within slider range\n",
    "                        actual_path_distance_filter = (mouse_x - 10) \n",
    "                        mouse_on_slider = True\n",
    "                    if (10 <= mouse_x <= 210) and (120 <= mouse_y <= 160):\n",
    "                        planned_path_distance_filter = (mouse_x - 10)\n",
    "                        mouse_on_slider = True\n",
    "                    \n",
    "        # Drag to pan\n",
    "        if dragging:\n",
    "            mouse_x, mouse_y = pygame.mouse.get_pos()\n",
    "            if not mouse_on_slider:\n",
    "                offset_x -= (last_mouse_pos[0] - mouse_x) / scale\n",
    "                offset_y -= (last_mouse_pos[1] - mouse_y) / scale\n",
    "            last_mouse_pos = (mouse_x, mouse_y)\n",
    "\n",
    "        # Clear the screen\n",
    "        screen.fill(BACKGROUND_COLOR)\n",
    "\n",
    "        draw_checkbox(10, 10, \"Show Actual Path\", show_actual_path)\n",
    "        draw_slider(10, 50, actual_path_distance_filter)  # Scale for display\n",
    "        \n",
    "\n",
    "        draw_checkbox(10, 90, \"Show Planned Path\", show_planned_path)\n",
    "        draw_slider(10, 130, planned_path_distance_filter)\n",
    "\n",
    "        \n",
    "        if show_actual_path:\n",
    "            filtered_actual_path = filter_path(actual_path, actual_path_distance_filter) # Filtered path based on slider values\n",
    "            draw_nodes_and_edges(filtered_actual_path, NODE_COLOR, EDGE_COLOR)\n",
    "        if show_planned_path:\n",
    "            filtered_planned_path = filter_path(planned_path, planned_path_distance_filter) # Filtered path based on slider values\n",
    "            draw_nodes_and_edges(filtered_planned_path, PLANNED_NODE_COLOR, PLANNED_EDGE_COLOR)\n",
    "\n",
    "        # Update the display\n",
    "        pygame.display.flip()\n",
    "        clock.tick(60)\n",
    "\n",
    "    pygame.quit()\n",
    "\n",
    "if not SKIP_VALIDATION:\n",
    "    print(\"Displaying the validation path summary...\")\n",
    "    visualize_paths(validation_results[\"planned_path\"], validation_results[\"actual_path\"])\n",
    "    print(\"Validation path summary closed!\")\n",
    "    print(\"Continuing with full simulation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare CARLA world for full simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add ego vehicle (with intrinsics and extrinsics from external configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Setting up the full simulation environment...\")\n",
    "\n",
    "reload_world()\n",
    "\n",
    "blueprint_name = \"vehicle.micro.microlino\"\n",
    "blueprint = blueprint_library.find(blueprint_name)\n",
    "blueprint.set_attribute('role_name','ego')\n",
    "transform = spawn_points[0]\n",
    "vehicle = world.spawn_actor(blueprint, transform)\n",
    "\n",
    "sensor_names = []\n",
    "sensor_types = []\n",
    "sensors = []\n",
    "\n",
    "for sensor_configuration in ego_vehicle_extrinsics.robot.links:\n",
    "    sensor_name = sensor_configuration.name\n",
    "\n",
    "    if \"CAM_\" in sensor_name:\n",
    "        blueprint_name = \"sensor.camera.rgb\"\n",
    "        sensor_type = blueprint_name\n",
    "        blueprint = blueprint_library.find(blueprint_name)\n",
    "        sensor_intrinsics = ego_vehicle_intrinsics.get(sensor_name, dict())\n",
    "\n",
    "        def calculate_fov(focal_length, image_width):\n",
    "            fov_radians = 2 * np.arctan(image_width / (2 * focal_length))\n",
    "            fov_degrees = np.degrees(fov_radians)\n",
    "            return fov_degrees\n",
    "        image_width = str(sensor_intrinsics.get(\"w\", 1600))\n",
    "        blueprint.set_attribute('image_size_x', image_width)\n",
    "        image_height = str(sensor_intrinsics.get(\"h\", 900))\n",
    "        blueprint.set_attribute('image_size_y', image_height)\n",
    "        focal_distance = float(sensor_intrinsics.get(\"fl\"))\n",
    "        field_of_view = str(calculate_fov(focal_distance, float(image_width)))\n",
    "        blueprint.set_attribute('fov', field_of_view)\n",
    "        \n",
    "        transform_matrix = ego_vehicle_extrinsics.get_T_from_to(\"center\", sensor_name)\n",
    "        transform_matrix = transform_to_carla(sensor_type, transform_matrix)\n",
    "        transform = matrix_to_transform(transform_matrix)\n",
    "        attached_to = vehicle\n",
    "        sensor = world.spawn_actor(blueprint, transform, attach_to=attached_to)\n",
    "        sensors.append(sensor)\n",
    "        sensor_types.append(sensor_type)\n",
    "        sensor_names.append(sensor_name)\n",
    "\n",
    "        ## Spawn additional DEPTH and SEMANTIC cams\n",
    "        blueprint_name = \"sensor.camera.depth\"\n",
    "        sensor_type = blueprint_name\n",
    "        blueprint = blueprint_library.find(blueprint_name)\n",
    "        blueprint.set_attribute('image_size_x', image_width)\n",
    "        blueprint.set_attribute('image_size_y', image_height)\n",
    "        blueprint.set_attribute('fov', field_of_view)\n",
    "        attached_to = vehicle\n",
    "        sensor = world.spawn_actor(blueprint, transform, attach_to=attached_to)\n",
    "        sensors.append(sensor)\n",
    "        sensor_types.append(sensor_type)\n",
    "        sensor_names.append(f\"DEPTH_{sensor_name}\")\n",
    "\n",
    "        blueprint_name = \"sensor.camera.instance_segmentation\"\n",
    "        sensor_type = blueprint_name\n",
    "        blueprint = blueprint_library.find(blueprint_name)\n",
    "        blueprint.set_attribute('image_size_x', image_width)\n",
    "        blueprint.set_attribute('image_size_y', image_height)\n",
    "        blueprint.set_attribute('fov', field_of_view)\n",
    "        attached_to = vehicle\n",
    "        sensor = world.spawn_actor(blueprint, transform, attach_to=attached_to)\n",
    "        sensors.append(sensor)\n",
    "        sensor_types.append(sensor_type)\n",
    "        sensor_names.append(f\"SEMANTIC_{sensor_name}\")\n",
    "\n",
    "    elif \"RADAR_\" in sensor_name:\n",
    "        blueprint_name = \"sensor.other.radar\"\n",
    "        sensor_type = blueprint_name\n",
    "        blueprint = blueprint_library.find(blueprint_name)     \n",
    "        blueprint.set_attribute('horizontal_fov', str(30.0)) \n",
    "        blueprint.set_attribute('vertical_fov', str(30.0)) \n",
    "        blueprint.set_attribute('points_per_second', str(1e5))\n",
    "        \n",
    "        transform_matrix = ego_vehicle_extrinsics.get_T_from_to(\"center\", sensor_name)\n",
    "        transform_matrix = transform_to_carla(sensor_type, transform_matrix)\n",
    "        transform = matrix_to_transform(transform_matrix)\n",
    "        attached_to = vehicle\n",
    "        sensor = world.spawn_actor(blueprint, transform, attach_to=attached_to)\n",
    "        sensors.append(sensor)\n",
    "        sensor_types.append(sensor_type)\n",
    "        sensor_names.append(sensor_name)\n",
    "\n",
    "    elif \"LIDAR_\" in sensor_name:\n",
    "        blueprint_name = \"sensor.lidar.ray_cast_semantic\"\n",
    "        sensor_type = blueprint_name\n",
    "        blueprint = blueprint_library.find(blueprint_name)\n",
    "        blueprint.set_attribute(\"channels\", str(128))  # Increase the number of channels\n",
    "        blueprint.set_attribute(\"points_per_second\", str(2000000))  # Increase the points per second\n",
    "        blueprint.set_attribute(\"range\", str(100))  # Increase the range\n",
    "        blueprint.set_attribute(\"rotation_frequency\", str(20))  # Increase the rotation frequency\n",
    "        blueprint.set_attribute(\"upper_fov\", str(30))  # Set upper field of view\n",
    "        blueprint.set_attribute(\"lower_fov\", str(-30))  # Set lower field of view\n",
    "        \n",
    "        transform_matrix = ego_vehicle_extrinsics.get_T_from_to(\"center\", sensor_name)\n",
    "        transform_matrix = transform_to_carla(sensor_type, transform_matrix)\n",
    "        transform = matrix_to_transform(transform_matrix)\n",
    "        attached_to = vehicle\n",
    "        sensor = world.spawn_actor(blueprint, transform, attach_to=attached_to)\n",
    "        sensors.append(sensor)\n",
    "        sensor_types.append(sensor_type)\n",
    "        sensor_names.append(sensor_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of sensors spawned: {len(sensors)}\")\n",
    "print(sensor_names)\n",
    "print(sensor_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add traffic (non-ego vehicles and pedestrians) to simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vehicles_to_simulation(n_vehicles: int=0):\n",
    "    print(\"Spawning vehicles...\")\n",
    "    # Connect to the CARLA server\n",
    "    world = client.get_world()\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "\n",
    "    # Load vehicle blueprints\n",
    "    vehicle_blueprints = blueprint_library.filter('vehicle.*')\n",
    "\n",
    "    # List to keep track of all actors\n",
    "    all_actors = []\n",
    "    spawn_points = world.get_map().get_spawn_points()\n",
    "    while (len(all_actors) < n_vehicles):\n",
    "        # Choose a random vehicle blueprint\n",
    "        vehicle_bp = random.choice(vehicle_blueprints)\n",
    "\n",
    "        # Spawn the vehicle\n",
    "        vehicle = None\n",
    "        while vehicle is None:\n",
    "            spawn_point = random.choice(spawn_points)\n",
    "            vehicle = world.try_spawn_actor(vehicle_bp, spawn_point)\n",
    "            time.sleep(0.1)\n",
    "        all_actors.append(vehicle)\n",
    "        # Set the vehicle to autopilot mode\n",
    "        vehicle.set_autopilot(True)\n",
    "    \n",
    "    port = traffic_manager.get_port()\n",
    "    for actor in all_actors:\n",
    "        actor.set_autopilot(True, port)\n",
    "    print(\"Vehicles spawned!\")\n",
    "\n",
    "def add_pedestrians_to_simulation(n_pedestrians: int=0) -> None:\n",
    "    print(\"Spawning pedestrians...\")\n",
    "    # Load pedestrian blueprints\n",
    "    pedestrian_blueprints = blueprint_library.filter('walker.pedestrian.*')\n",
    "    walker_controller_bp = blueprint_library.find('controller.ai.walker')\n",
    "\n",
    "    # List to keep track of all actors\n",
    "    all_actors = []\n",
    "\n",
    "    spawn_points = world.get_map().get_spawn_points()\n",
    "    while (len(all_actors) < n_pedestrians):\n",
    "        # Choose a random pedestrian blueprint\n",
    "        pedestrian_bp = random.choice(pedestrian_blueprints)        \n",
    "\n",
    "        # Spawn the pedestrian\n",
    "        pedestrian = None\n",
    "        while pedestrian is None:\n",
    "            spawn_point = random.choice(spawn_points)\n",
    "            pedestrian = world.try_spawn_actor(pedestrian_bp, spawn_point)\n",
    "            time.sleep(0.1)\n",
    "        all_actors.append(pedestrian)\n",
    "\n",
    "        # Spawn the walker AI controller\n",
    "        walker_controller = None\n",
    "        while walker_controller is None:\n",
    "            walker_controller = world.try_spawn_actor(walker_controller_bp, carla.Transform(), pedestrian)\n",
    "            time.sleep(0.1)\n",
    "        all_actors.append(walker_controller)\n",
    "        \n",
    "        # Start the AI controller\n",
    "        walker_controller.start()\n",
    "        walker_controller.go_to_location(world.get_random_location_from_navigation())\n",
    "        walker_controller.set_max_speed(1 + random.random())  # Random speed between 1 and 2 m/s\n",
    "    print(\"Pedestrians spawned!\")\n",
    "\n",
    "ai_vehicles = add_vehicles_to_simulation(n_vehicles=15)\n",
    "ai_pedestrians = add_pedestrians_to_simulation(n_pedestrians=10)\n",
    "\n",
    "print(\"Simulation environment setup completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Toggle off all buildings (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TOGGLE_OFF_BUILDINGS:\n",
    "    print(\"Turing off buildings...\")\n",
    "    # Toggle off all buildings \n",
    "    objs = world.get_environment_objects(carla.CityObjectLabel.Buildings)\n",
    "    building_ids = [obj.id for obj in objs]\n",
    "    # Toggle buildings off\n",
    "    world.enable_environment_objects(building_ids, False)\n",
    "    print(\"Buildings are turned off.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run full simulation in CARLA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filesystem methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_all_in_directory(target_directory):\n",
    "    if os.path.exists(target_directory):\n",
    "        for filename in os.listdir(target_directory):\n",
    "            file_path = os.path.join(target_directory, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.remove(file_path) \n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)\n",
    "            except Exception as e:\n",
    "                print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "\n",
    "\n",
    "def create_filename_from_timestamp(timestamp):\n",
    "    SECONDS_TO_NANOSECONDS = 1000000000\n",
    "    filename = str(math.trunc(timestamp * SECONDS_TO_NANOSECONDS))\n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### General sensor processing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_point_cloud_from_left_to_right_hand_system(point_cloud):\n",
    "    flip_yz_matrix = np.array([\n",
    "                        [-1, 0,  0, 0],\n",
    "                        [ 0, 1,  0, 0],\n",
    "                        [ 0, 0,  1, 0],\n",
    "                        [ 0, 0,  0, 1]\n",
    "                    ])\n",
    "    rotation = rotation_matrix('z', np.pi / 2)\n",
    "    # tf_to_SE3 = transform_from_carla(sensor_type)\n",
    "    tf_to_SE3 = flip_yz_matrix @ rotation\n",
    "    point_cloud.transform(tf_to_SE3)\n",
    "    return point_cloud\n",
    "\n",
    "def save_sensor_position(raw_data, target_directory, sensor_type=None):\n",
    "    if not os.path.exists(target_directory):\n",
    "        os.makedirs(target_directory, exist_ok=True)\n",
    "    transform_matrix = raw_data.transform.get_matrix()\n",
    "    \n",
    "    if \"camera\" in sensor_type:\n",
    "        rotation_inv = transform_from_carla(sensor_type)\n",
    "    else:\n",
    "        rotation = rotation_matrix('z', np.pi / 2)\n",
    "        rotation_inv = np.linalg.inv(rotation)\n",
    "\n",
    "    flip_xz_matrix = np.array([\n",
    "        [1,  0,  0, 0],\n",
    "        [0, -1,  0, 0],\n",
    "        [0,  0,  1, 0],\n",
    "        [0,  0,  0, 1]\n",
    "    ])\n",
    "\n",
    "    flip_yz_matrix = np.array([\n",
    "        [-1, 0,  0, 0],\n",
    "        [ 0, 1,  0, 0],\n",
    "        [ 0, 0,  1, 0],\n",
    "        [ 0, 0,  0, 1]\n",
    "    ])\n",
    "    transform_matrix = flip_xz_matrix @ transform_matrix @ rotation_inv @ flip_yz_matrix\n",
    "    # if \"camera\" in sensor_type:\n",
    "    #     rotate_z_forward = rotation_matrix('x', -np.pi / 2)\n",
    "    #     transform_matrix = np.dot(transform_matrix, rotate_z_forward)\n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".npy\"\n",
    "    filepath = os.path.join(target_directory, filename)\n",
    "    np.save(filepath, transform_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Camera Methods (RGB, Semantic and Depth) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_camera_image(raw_data, target_directory):    \n",
    "    if not os.path.exists(target_directory):\n",
    "        os.makedirs(target_directory, exist_ok=True)\n",
    "    rgb_image = np.reshape(raw_data.raw_data, (raw_data.height, raw_data.width, 4))[:, :, :3] # Remove alpha channel\n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".png\"\n",
    "    filepath = os.path.join(target_directory, filename)\n",
    "    cv2.imwrite(filepath, rgb_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Radar Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_radar_readings(raw_data, target_directory):\n",
    "    if not os.path.exists(target_directory):\n",
    "        os.makedirs(target_directory, exist_ok=True)\n",
    "    radar_points_list = []\n",
    "    for measurement in raw_data:\n",
    "        azi = math.degrees(measurement.azimuth)\n",
    "        alt = math.degrees(measurement.altitude)\n",
    "        fw_vec = carla.Vector3D(x=measurement.depth)\n",
    "        carla.Transform(\n",
    "            carla.Location(),\n",
    "            carla.Rotation(pitch=alt,yaw=azi,roll=0)\n",
    "        ).transform(fw_vec)\n",
    "        radar_points_list.append([fw_vec.x, fw_vec.y, fw_vec.z])\n",
    "    \n",
    "    points = np.array(radar_points_list)\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(points)\n",
    "    point_cloud = convert_point_cloud_from_left_to_right_hand_system(point_cloud)\n",
    "    \n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".ply\"\n",
    "    filepath = os.path.join(target_directory, filename)\n",
    "    o3d.io.write_point_cloud(filepath, point_cloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lidar methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_lidar_readings(raw_data, target_directory):\n",
    "    if not os.path.exists(target_directory):\n",
    "        os.makedirs(target_directory, exist_ok=True)\n",
    "    points = np.array([(detection.point.x, detection.point.y, detection.point.z) for detection in raw_data])\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(points)\n",
    "    point_cloud = convert_point_cloud_from_left_to_right_hand_system(point_cloud)\n",
    "\n",
    "    # Save the point cloud to a .ply file\n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".ply\"\n",
    "    filepath = os.path.join(target_directory, filename)\n",
    "    o3d.io.write_point_cloud(filepath, point_cloud)\n",
    "\n",
    "def save_semantic_lidar_readings(raw_data, target_directory):\n",
    "    if not os.path.exists(target_directory):\n",
    "        os.makedirs(target_directory, exist_ok=True)\n",
    "    lidar_data = np.array([(detection.point.x, detection.point.y, detection.point.z, detection.object_tag) for detection in raw_data])\n",
    "    points = lidar_data[:, :3]\n",
    "    semantic_tags = lidar_data[:, 3] \n",
    "    semantic_colors_rgb = np.zeros((len(semantic_tags), 3))\n",
    "    semantic_colors_rgb[:, 0] = semantic_tags\n",
    "    semantic_colors_normalized = semantic_colors_rgb / 255.0\n",
    "    \n",
    "    # Create an Open3D point cloud object\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(points)\n",
    "    point_cloud.colors = o3d.utility.Vector3dVector(semantic_colors_normalized)\n",
    "    point_cloud = convert_point_cloud_from_left_to_right_hand_system(point_cloud)\n",
    "\n",
    "    # Save the point cloud to a .ply file\n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".ply\"\n",
    "    filepath = os.path.join(target_directory, filename)\n",
    "    o3d.io.write_point_cloud(filepath, point_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_all_in_directory(SIMULATION_DATA_OUTPUT_PATH)\n",
    "\n",
    "print(\"Starting the simulation...\")\n",
    "cv2.namedWindow(\"Press Q to stop simulation\")\n",
    "cv2.imshow(\"Press Q to stop simulation\", np.zeros((1,1)))\n",
    "\n",
    "vehicle_control_agent = BasicAgent(vehicle, target_speed=15)\n",
    "vehicle_control_agent.ignore_traffic_lights()\n",
    "agent_path = get_agent_path(episode_ego_vehicle_path)\n",
    "vehicle_control_agent.set_destination(agent_path.pop(0))\n",
    "\n",
    "try:\n",
    "    with CarlaSyncMode(world, sensors, fps=10) as sync_mode:\n",
    "        print(\"Driving to the start of the path...\")\n",
    "        while vehicle_control_agent.done() is False:\n",
    "            simulated_results = sync_mode.tick()[1:]\n",
    "            if \"CAM_FRONT\" in sensor_names:\n",
    "                front_cam_sensor = simulated_results[sensor_names.index(\"CAM_FRONT\")]\n",
    "                front_cam_sensor_image =  np.reshape(np.copy(front_cam_sensor.raw_data), (front_cam_sensor.height, front_cam_sensor.width, 4))\n",
    "                cv2.imshow(\"Driving to start of the path...\", front_cam_sensor_image)\n",
    "            vehicle.apply_control(vehicle_control_agent.run_step())\n",
    "            \n",
    "            if (cv2.waitKey(1) == ord('q')):\n",
    "                break\n",
    "        cv2.destroyWindow(\"Driving to start of the path...\")\n",
    "        print(\"Arrived at the start of the path!\")\n",
    "\n",
    "        print(\"Driving on path...\")\n",
    "        while True:\n",
    "            simulation_results = sync_mode.tick(timeout=100.0)[1:]\n",
    "            for i in range(len(simulation_results)):\n",
    "                sensor = sensors[i]\n",
    "                sensor_data = simulation_results[i]\n",
    "                sensor_name = sensor_names[i].replace(\"base_link_to_\", \"\")\n",
    "                sensor_type = sensor_types[i]\n",
    "\n",
    "                sensor_data_path = os.path.join(SIMULATION_DATA_OUTPUT_PATH, sensor_name)\n",
    "                if (\"camera.rgb\" in sensor_type) or (\"camera.instance_segmentation\" in sensor_type) or (\"camera.depth\" in sensor_type):\n",
    "                    save_camera_image(sensor_data, sensor_data_path)\n",
    "                elif (\"sensor.other.radar\" in sensor_type):\n",
    "                    save_radar_readings(sensor_data, sensor_data_path)\n",
    "                elif (\"sensor.lidar.ray_cast_semantic\" in sensor_type):\n",
    "                    save_semantic_lidar_readings(sensor_data, sensor_data_path)\n",
    "                elif (\"sensor.lidar\" in sensor_type):\n",
    "                    save_lidar_readings(sensor_data, sensor_data_path)\n",
    "                save_sensor_position(sensor_data, sensor_data_path, sensor_type=sensor_type)\n",
    "                \n",
    "            if vehicle_control_agent.done():\n",
    "                print(f\"{datetime.now()} Checkpoint reached. Ego vehicle has reached {len(episode_ego_vehicle_path) - len(agent_path)}/{len(episode_ego_vehicle_path)} planned path points.\")\n",
    "                if len(agent_path) == 0:\n",
    "                    break\n",
    "                vehicle_control_agent.set_destination(agent_path.pop(0))\n",
    "            vehicle.apply_control(vehicle_control_agent.run_step())\n",
    "\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "\n",
    "        print(\"Driving on path finished!\")\n",
    "except RuntimeError as error:\n",
    "    print(\"An error occurred during the simulation.\")\n",
    "    print(error)\n",
    "finally:\n",
    "    cv2.destroyAllWindows()\n",
    "    for sensor in sensors:\n",
    "        sensor.stop()\n",
    "        sensor.destroy()\n",
    "    vehicle.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Simulation finished!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
