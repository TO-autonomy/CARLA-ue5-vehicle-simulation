{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import queue\n",
    "import shutil \n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "from enum import Enum\n",
    "from datetime import datetime\n",
    "\n",
    "import carla\n",
    "import numpy as np\n",
    "import urdf_parser_py.urdf as urdf\n",
    "from scipy.spatial.transform import Rotation   \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import open3d as o3d\n",
    "import cv2\n",
    "import pygame\n",
    "\n",
    "from classes.CARLASemantics_v0_9_15 import SemanticColors, SemanticTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the CARLA Python API path\n",
    "CURRENT_WORKING_DIR = os.getcwd()\n",
    "CARLA_PYTHON_API_PATH = os.path.join(CURRENT_WORKING_DIR, \"CARLASimulator\", \"PythonAPI\", \"carla\")\n",
    "if CARLA_PYTHON_API_PATH not in sys.path:\n",
    "    sys.path.append(CARLA_PYTHON_API_PATH)\n",
    "\n",
    "# Import the BasicAgent\n",
    "try:\n",
    "    from agents.navigation.basic_agent import BasicAgent\n",
    "    from agents.navigation.behavior_agent import BehaviorAgent\n",
    "except ImportError as error:\n",
    "    raise ImportError(f\"FATAL ERROR: Unable to import CARLA autonomous driving agent BasicAgent due to missing PythonAPI. The API is included in the simulator installation package (not included with 'import carla'). Setup the CARLA simulator repository and add the correct PythonAPI path above. ({error})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to CARLA server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(100)\n",
    "world = client.get_world()\n",
    "map = world.get_map()\n",
    "\n",
    "blueprint_library = world.get_blueprint_library()\n",
    "spawn_points = world.get_map().get_spawn_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_world():\n",
    "    global world, map, blueprint_library, spawn_points, traffic_manager\n",
    "    world = client.reload_world()\n",
    "    map = world.get_map()\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    spawn_points = map.get_spawn_points()\n",
    "    traffic_manager = client.get_trafficmanager()\n",
    "\n",
    "def load_world(map_name=\"Town01\", timeout=10.0):\n",
    "    global world, map, blueprint_library, spawn_points, traffic_manager\n",
    "    client.set_timeout(timeout)\n",
    "    world = client.load_world(map_name)\n",
    "    map = world.get_map()\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    spawn_points = map.get_spawn_points()\n",
    "    traffic_manager = client.get_trafficmanager()\n",
    "\n",
    "load_world(map_name=\"Town01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarlaSyncMode(object):\n",
    "    \"\"\"\n",
    "        with CarlaSyncMode(world, sensors) as sync_mode:\n",
    "            while True:\n",
    "                data = sync_mode.tick(timeout=1.0)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, world, sensors, **kwargs):\n",
    "        self.world = world\n",
    "        self.sensors = sensors\n",
    "        self.frame = None\n",
    "        self.delta_seconds = 1.0 / kwargs.get('fps', 10)\n",
    "        self._queues = []\n",
    "        self._settings = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        self._settings = self.world.get_settings()\n",
    "        self.frame = self.world.apply_settings(carla.WorldSettings(\n",
    "            no_rendering_mode=False,\n",
    "            synchronous_mode=True,\n",
    "            fixed_delta_seconds=self.delta_seconds,\n",
    "            ))\n",
    "\n",
    "        def make_queue(register_event):\n",
    "            q = queue.Queue()\n",
    "            register_event(q.put)\n",
    "            self._queues.append(q)\n",
    "\n",
    "        make_queue(self.world.on_tick)\n",
    "        for sensor in self.sensors:\n",
    "            make_queue(sensor.listen)\n",
    "        return self\n",
    "\n",
    "    def tick(self, timeout=300):\n",
    "        self.frame = self.world.tick()\n",
    "        data = [self._retrieve_data(q, timeout) for q in self._queues]\n",
    "        assert all(x.frame == self.frame for x in data)\n",
    "        return data\n",
    "\n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        self.world.apply_settings(self._settings)\n",
    "\n",
    "    def _retrieve_data(self, sensor_queue, timeout):\n",
    "        while True:\n",
    "            data = sensor_queue.get(timeout=timeout)\n",
    "            if data.frame == self.frame:\n",
    "                return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CARLA transformation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_to_transform(matrix):\n",
    "    # Ensure matrix is a NumPy array\n",
    "    if not isinstance(matrix, np.ndarray):\n",
    "        matrix = np.array(matrix)\n",
    "\n",
    "    # Extract translation\n",
    "    location = carla.Location(x=matrix[0, 3], y=(-matrix[1, 3]), z=matrix[2, 3])\n",
    "\n",
    "    roll, pitch, yaw = Rotation.from_matrix(matrix[:3, :3]).as_euler('xyz', degrees=True)\n",
    "    rotation = carla.Rotation(pitch=(-pitch), yaw=(-yaw), roll=roll)\n",
    "    \n",
    "    # Create and return carla.Transform\n",
    "    return carla.Transform(location, rotation)\n",
    "\n",
    "\n",
    "def build_transform_matrix(rotation, translation):\n",
    "    m = np.eye(4)\n",
    "    m[:3, :3] = rotation\n",
    "    m[:3, 3] = translation\n",
    "    return m\n",
    "\n",
    "\n",
    "def rotation_matrix(axis, angle):\n",
    "    \"\"\"\n",
    "    Create a rotation matrix for a given axis and angle.\n",
    "    \"\"\"\n",
    "    if axis == 'x':\n",
    "        return np.array([\n",
    "            [1, 0, 0, 0],\n",
    "            [0, np.cos(angle), -np.sin(angle), 0],\n",
    "            [0, np.sin(angle), np.cos(angle), 0],\n",
    "            [0, 0, 0, 1]\n",
    "        ])\n",
    "    elif axis == 'y':\n",
    "        return np.array([\n",
    "            [np.cos(angle), 0, np.sin(angle), 0],\n",
    "            [0, 1, 0, 0],\n",
    "            [-np.sin(angle), 0, np.cos(angle), 0],\n",
    "            [0, 0, 0, 1]\n",
    "        ])\n",
    "    elif axis == 'z':\n",
    "        return np.array([\n",
    "            [np.cos(angle), -np.sin(angle), 0, 0],\n",
    "            [np.sin(angle), np.cos(angle), 0, 0],\n",
    "            [0, 0, 1, 0],\n",
    "            [0, 0, 0, 1]\n",
    "        ])\n",
    "\n",
    "def reflection_matrix():\n",
    "    \"\"\"\n",
    "    Create a reflection matrix to flip the Y-axis.\n",
    "    \"\"\"\n",
    "    return np.array([\n",
    "        [1, 0, 0, 0],\n",
    "        [0, -1, 0, 0],\n",
    "        [0, 0, 1, 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ])\n",
    "\n",
    "def transform_to_carla(sensor_type, transformation):\n",
    "    \"\"\"\n",
    "    Convert sensor transformation to CARLA format.\n",
    "    \"\"\"\n",
    "    sensor_type = sensor_type.lower().strip()\n",
    "    if sensor_type in ['camera', 'sensor.camera', 'sensor.camera.rgb', 'sensor.camera.semantic_segmentation', 'sensor.camera.depth']:\n",
    "        rotation1 = rotation_matrix('z', np.pi / 2)\n",
    "        rotation2 = rotation_matrix('y', -np.pi / 2)\n",
    "        rotation = np.dot(rotation1, rotation2)\n",
    "    elif sensor_type in ['lidar', 'sensor.lidar', 'sensor.lidar.ray_cast', 'sensor.lidar.ray_cast_semantic']:\n",
    "        rotation = rotation_matrix('z', np.pi / 2)\n",
    "    elif sensor_type in ['radar', 'sensor.other.radar']:\n",
    "        rotation = np.eye(4)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown sensor type\")\n",
    "    tf = np.dot(transformation, rotation)\n",
    "    return tf\n",
    "\n",
    "def transform_from_carla(sensor_type, transformation):\n",
    "    \"\"\"\n",
    "    Convert sensor transformation from CARLA format.\n",
    "    \"\"\"\n",
    "    sensor_type = sensor_type.lower().strip()\n",
    "    if sensor_type in ['camera', 'sensor.camera', 'sensor.camera.rgb', 'sensor.camera.semantic_segmentation', 'sensor.camera.depth']:\n",
    "        rotation1 = rotation_matrix('z', -np.pi / 2)\n",
    "        rotation2 = rotation_matrix('y', np.pi / 2)\n",
    "        rotation = np.dot(rotation2, rotation1)\n",
    "    elif sensor_type in ['lidar', 'sensor.lidar', 'sensor.lidar.ray_cast', 'sensor.lidar.ray_cast_semantic']:  \n",
    "        rotation = rotation_matrix('z', -np.pi / 2)\n",
    "    elif sensor_type in ['radar', 'sensor.other.radar']:\n",
    "        rotation = np.eye(4)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown sensor type\")\n",
    "    tf = np.dot(transformation, rotation)\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run path validation in CARLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planned_path_json = dict()\n",
    "with open('/home/leppsalu/Desktop/Github/CARLA-vehicle-simulation/src/config/town2.path.json') as path_file:\n",
    "    planned_path_json = json.load(path_file)\n",
    "planned_path = planned_path_json[\"route\"]\n",
    "planned_path = planned_path[0:2]\n",
    "\n",
    "def get_agent_path(coordinates):\n",
    "    path = []\n",
    "    for x, y, z in coordinates:\n",
    "        location = carla.Location(x=x, y=y, z=z)\n",
    "        waypoint = map.get_waypoint(\n",
    "            location,\n",
    "            project_to_road=True, \n",
    "            lane_type=(carla.LaneType.Driving))\n",
    "        waypoint_location = waypoint.transform.location\n",
    "        path.append(waypoint_location)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_path():\n",
    "    reload_world()\n",
    "\n",
    "    cv2.namedWindow(\"Press Q to stop simulation\")\n",
    "    cv2.imshow(\"Press Q to stop simulation\", np.zeros((1,1)))\n",
    "\n",
    "    blueprint_name = \"vehicle.micro.microlino\"\n",
    "    blueprint = blueprint_library.find(blueprint_name)\n",
    "    transform = spawn_points[0]\n",
    "    validation_vehicle = world.spawn_actor(blueprint, transform)\n",
    "\n",
    "    blueprint = blueprint_library.find(\"sensor.camera.rgb\")\n",
    "    blueprint.set_attribute('image_size_x', str(720))\n",
    "    blueprint.set_attribute('image_size_y', str(480))\n",
    "\n",
    "    transform_matrix = carla.Transform(carla.Location(x=1.7, y=0.0, z=1.5), carla.Rotation(roll=0, pitch=0, yaw=0)).get_matrix()\n",
    "    transform = matrix_to_transform(transform_matrix)\n",
    "    sensor = world.spawn_actor(blueprint, transform, attach_to=validation_vehicle)\n",
    "    validation_vehicle_control_agent = BasicAgent(validation_vehicle)#, target_speed=15)\n",
    "    agent_path = get_agent_path(planned_path)\n",
    "    validation_vehicle_control_agent.set_destination(agent_path.pop(0))\n",
    "\n",
    "    agent_path_completed = False\n",
    "    try:\n",
    "        with CarlaSyncMode(world, [sensor], fps=10) as sync_mode:\n",
    "            print(\"Driving to the start of the path...\")\n",
    "            while validation_vehicle_control_agent.done() is False:\n",
    "                if (cv2.waitKey(1) == ord('q')):\n",
    "                    break\n",
    "                simulated_results = sync_mode.tick()[1:]\n",
    "                cam_sensor = simulated_results[0]\n",
    "                cam_sensor_image =  np.reshape(np.copy(cam_sensor.raw_data), (cam_sensor.height, cam_sensor.width, 4))\n",
    "                cv2.imshow(\"CAM_FRONT\", cam_sensor_image)\n",
    "\n",
    "                validation_vehicle.apply_control(validation_vehicle_control_agent.run_step())\n",
    "            print(\"Arrived at the start of the path!\")\n",
    "\n",
    "            print(\"Driving on path...\")\n",
    "            actual_path = []\n",
    "            while True:\n",
    "                if (cv2.waitKey(1) == ord('q')):\n",
    "                    break\n",
    "\n",
    "                simulated_results = sync_mode.tick()[1:]\n",
    "                cam_sensor = simulated_results[0]\n",
    "                cam_sensor_image =  np.reshape(np.copy(cam_sensor.raw_data), (cam_sensor.height, cam_sensor.width, 4))\n",
    "                cv2.imshow(\"CAM_FRONT\", cam_sensor_image)\n",
    "\n",
    "                location = validation_vehicle.get_location()\n",
    "                actual_path.append((location.x, location.y, location.z))\n",
    "                \n",
    "                if validation_vehicle_control_agent.done():\n",
    "                    print(f\"{datetime.now()} Checkpoint reached. Validation vehicle has reached {len(planned_path) - len(agent_path)}/{len(planned_path)} planned path points.\")\n",
    "                    if (agent_path == []):\n",
    "                        agent_path_completed = True\n",
    "                        break\n",
    "                    validation_vehicle_control_agent.set_destination(agent_path.pop(0))\n",
    "                validation_vehicle.apply_control(validation_vehicle_control_agent.run_step())\n",
    "            print(\"Drive finished!\")\n",
    "    except RuntimeError as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        cv2.destroyAllWindows()\n",
    "        validation_vehicle.destroy()\n",
    "\n",
    "    assert agent_path_completed, \"Validation failed. The vehicle could not complete the planned path.\"\n",
    "\n",
    "    return planned_path, actual_path\n",
    "\n",
    "\n",
    "SKIP_VALIDATION = True\n",
    "validation_results = dict()\n",
    "if not SKIP_VALIDATION:\n",
    "    planned_path, actual_path = validate_path()\n",
    "    validation_results[\"planned_path\"] = planned_path\n",
    "    validation_results[\"actual_path\"] = actual_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_path(coords, min_distance):\n",
    "    def distance(point1, point2):\n",
    "        return math.sqrt((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)\n",
    "    filtered_coords = []\n",
    "    for i in range(len(coords)):\n",
    "        if (i == 0) or (i == (len(coords)-1)) or distance(filtered_coords[-1], coords[i]) >= min_distance:\n",
    "            filtered_coords.append(coords[i])\n",
    "    return filtered_coords\n",
    "\n",
    "def visualize_paths(planned_path, actual_path):\n",
    "    # Initialize Pygame\n",
    "    pygame.init()\n",
    "\n",
    "    # Constants\n",
    "    WIDTH, HEIGHT = 800, 600\n",
    "    BACKGROUND_COLOR = (255, 255, 255)\n",
    "    NODE_COLOR = (0, 0, 255)\n",
    "    EDGE_COLOR = (0, 0, 0)  # For the planned coordinates\n",
    "    PLANNED_NODE_COLOR = (0, 255, 0)\n",
    "    PLANNED_EDGE_COLOR = (0, 200, 0)\n",
    "    NODE_RADIUS = 5\n",
    "    ARROW_SIZE = 10\n",
    "    FONT_COLOR = (0, 0, 0)\n",
    "\n",
    "    # Create the screen\n",
    "    screen = pygame.display.set_mode((WIDTH, HEIGHT))\n",
    "    pygame.display.set_caption(\"Validation path summary\")\n",
    "\n",
    "    # Zoom and pan variables\n",
    "    scale = 1.0\n",
    "    offset_x, offset_y = 0, 0\n",
    "    zoom_factor = 1.1\n",
    "    dragging = False\n",
    "    last_mouse_pos = (0, 0)\n",
    "\n",
    "    # Checkbox states\n",
    "    show_actual_path = True\n",
    "    show_planned_path = True\n",
    "\n",
    "    # Slider values\n",
    "    actual_path_distance_filter = 10.0\n",
    "    planned_path_distance_filter = 10.0\n",
    "\n",
    "    def draw_arrow(surface, start, end, color):\n",
    "        pygame.draw.line(surface, color, start, end, 2)\n",
    "        \n",
    "        angle = math.atan2(end[1] - start[1], end[0] - start[0])\n",
    "        left_angle = angle + math.pi / 6\n",
    "        right_angle = angle - math.pi / 6\n",
    "\n",
    "        left_point = (end[0] - ARROW_SIZE * math.cos(left_angle),\n",
    "                      end[1] - ARROW_SIZE * math.sin(left_angle))\n",
    "        right_point = (end[0] - ARROW_SIZE * math.cos(right_angle),\n",
    "                       end[1] - ARROW_SIZE * math.sin(right_angle))\n",
    "\n",
    "        pygame.draw.polygon(surface, color, [end, left_point, right_point])\n",
    "\n",
    "    def draw_nodes_and_edges(coords, node_color, edge_color):\n",
    "        for i, (x, y, z) in enumerate(coords):\n",
    "            scaled_x = (x + offset_x) * scale\n",
    "            scaled_y = (y + offset_y) * scale\n",
    "            \n",
    "            pygame.draw.circle(screen, node_color, (int(scaled_x), int(scaled_y)), NODE_RADIUS)\n",
    "            \n",
    "            font = pygame.font.Font(None, 24)\n",
    "            text_surface = font.render(str(i), True, FONT_COLOR)\n",
    "            screen.blit(text_surface, (scaled_x + 10, scaled_y - 10))\n",
    "            \n",
    "            if i < len(coords) - 1:\n",
    "                next_x, next_y, _ = coords[i + 1]\n",
    "                next_scaled_x = (next_x + offset_x) * scale\n",
    "                next_scaled_y = (next_y + offset_y) * scale\n",
    "                draw_arrow(screen, (int(scaled_x), int(scaled_y)), (int(next_scaled_x), int(next_scaled_y)), edge_color)\n",
    "\n",
    "    def draw_checkbox(x, y, label, checked):\n",
    "        pygame.draw.rect(screen, (0, 0, 0), (x, y, 20, 20), 2)\n",
    "        if checked:\n",
    "            pygame.draw.rect(screen, (0, 255, 0), (x + 2, y + 2, 16, 16))\n",
    "\n",
    "        font = pygame.font.Font(None, 24)\n",
    "        text_surface = font.render(label, True, FONT_COLOR)\n",
    "        screen.blit(text_surface, (x + 30, y))\n",
    "\n",
    "    def draw_slider(x, y, value):\n",
    "        pygame.draw.rect(screen, (200, 200, 200), (x, y, 200, 20))  # Slider background\n",
    "        pygame.draw.rect(screen, (100, 100, 100), (x + int(value), y, 10, 20))  # Slider handle\n",
    "\n",
    "    # Main loop\n",
    "    clock = pygame.time.Clock()\n",
    "    running = True\n",
    "    \n",
    "    while running:\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                running = False\n",
    "            elif event.type == pygame.KEYDOWN:\n",
    "                if event.key == pygame.K_ESCAPE:\n",
    "                    running = False\n",
    "            \n",
    "            # Zoom with mouse scroll wheel\n",
    "            elif event.type == pygame.MOUSEBUTTONDOWN:\n",
    "                if event.button == 4:  # Scroll up\n",
    "                    scale *= zoom_factor\n",
    "                elif event.button == 5:  # Scroll down\n",
    "                    scale /= zoom_factor\n",
    "                elif event.button == 1:  # Left mouse button\n",
    "                    dragging = True\n",
    "                    last_mouse_pos = pygame.mouse.get_pos()\n",
    "\n",
    "            elif event.type == pygame.MOUSEBUTTONUP:\n",
    "                if event.button == 1:  # Left mouse button\n",
    "                    dragging = False\n",
    "                # Click on checkboxes\n",
    "                mouse_pos = pygame.mouse.get_pos()\n",
    "                if 10 <= mouse_pos[0] <= 30 and 10 <= mouse_pos[1] <= 30:\n",
    "                    show_actual_path = not show_actual_path\n",
    "                if 10 <= mouse_pos[0] <= 30 and 90 <= mouse_pos[1] <= 110:\n",
    "                    show_planned_path = not show_planned_path\n",
    "\n",
    "            elif event.type == pygame.MOUSEMOTION:\n",
    "                mouse_on_slider = False\n",
    "                if dragging:\n",
    "                    mouse_x, mouse_y = pygame.mouse.get_pos()\n",
    "                    if (10 <= mouse_x <= 210) and (40 <= mouse_y <= 80):  # Adjust value within slider range\n",
    "                        actual_path_distance_filter = (mouse_x - 10) \n",
    "                        mouse_on_slider = True\n",
    "                    if (10 <= mouse_x <= 210) and (120 <= mouse_y <= 160):\n",
    "                        planned_path_distance_filter = (mouse_x - 10)\n",
    "                        mouse_on_slider = True\n",
    "                    \n",
    "        # Drag to pan\n",
    "        if dragging:\n",
    "            mouse_x, mouse_y = pygame.mouse.get_pos()\n",
    "            if not mouse_on_slider:\n",
    "                offset_x -= (last_mouse_pos[0] - mouse_x) / scale\n",
    "                offset_y -= (last_mouse_pos[1] - mouse_y) / scale\n",
    "            last_mouse_pos = (mouse_x, mouse_y)\n",
    "\n",
    "        # Clear the screen\n",
    "        screen.fill(BACKGROUND_COLOR)\n",
    "\n",
    "        draw_checkbox(10, 10, \"Show Actual Path\", show_actual_path)\n",
    "        draw_slider(10, 50, actual_path_distance_filter)  # Scale for display\n",
    "        \n",
    "\n",
    "        draw_checkbox(10, 90, \"Show Planned Path\", show_planned_path)\n",
    "        draw_slider(10, 130, planned_path_distance_filter)\n",
    "\n",
    "        \n",
    "        if show_actual_path:\n",
    "            filtered_actual_path = filter_path(actual_path, actual_path_distance_filter) # Filtered path based on slider values\n",
    "            draw_nodes_and_edges(filtered_actual_path, NODE_COLOR, EDGE_COLOR)\n",
    "        if show_planned_path:\n",
    "            filtered_planned_path = filter_path(planned_path, planned_path_distance_filter) # Filtered path based on slider values\n",
    "            draw_nodes_and_edges(filtered_planned_path, PLANNED_NODE_COLOR, PLANNED_EDGE_COLOR)\n",
    "\n",
    "        # Update the display\n",
    "        pygame.display.flip()\n",
    "        clock.tick(60)\n",
    "\n",
    "    pygame.quit()\n",
    "\n",
    "if not SKIP_VALIDATION:\n",
    "    visualize_paths(validation_results[\"planned_path\"], validation_results[\"actual_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare CARLA world for full simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add ego vehicle (with intrinsics and extrinsics from external configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class URDFParser:\n",
    "    def __init__(self, urdf_file):\n",
    "        self.urdf_file = urdf_file\n",
    "        self.robot = urdf.URDF.from_xml_file(urdf_file)\n",
    "        self.root = self.robot.get_root()\n",
    "\n",
    "    def compute_chain_transform(self, chain):\n",
    "        transform = np.eye(4)\n",
    "        \n",
    "        for joint in chain:\n",
    "            if joint not in self.robot.joint_map:\n",
    "                continue\n",
    "            \n",
    "            joint_info = self.robot.joint_map[joint]\n",
    "            rpy = joint_info.origin.rpy\n",
    "            xyz = joint_info.origin.xyz\n",
    "            rotation = Rotation.from_euler('xyz', rpy).as_matrix()\n",
    "            translation = np.array(xyz)\n",
    "            T = build_transform_matrix(rotation, translation)\n",
    "            transform = np.dot(transform, T)\n",
    "        \n",
    "        return transform\n",
    "\n",
    "    def get_T_from_to(self, start_frame, end_frame):\n",
    "        chain_1 = self.robot.get_chain(self.root, start_frame)\n",
    "        chain_2 = self.robot.get_chain(self.root, end_frame)\n",
    "        T1 = self.compute_chain_transform(chain_1)\n",
    "        T2 = self.compute_chain_transform(chain_2)\n",
    "        return np.dot(np.linalg.inv(T1), T2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_world()\n",
    "\n",
    "blueprint_name = \"vehicle.micro.microlino\"\n",
    "blueprint = blueprint_library.find(blueprint_name)\n",
    "blueprint.set_attribute('role_name','ego')\n",
    "transform = spawn_points[0]\n",
    "vehicle = world.spawn_actor(blueprint, transform)\n",
    "\n",
    "sensor_names = []\n",
    "sensor_types = []\n",
    "sensors = []\n",
    "\n",
    "axes = []\n",
    "\n",
    "extrinsics = URDFParser('config/carla_extrinsics.urdf')\n",
    "intrinsics = dict()\n",
    "with open('config/carla_intrinsics.json') as intrinsics_file:\n",
    "    intrinsics = json.load(intrinsics_file)\n",
    "\n",
    "for sensor_configuration in extrinsics.robot.links:\n",
    "    sensor_name = sensor_configuration.name\n",
    "\n",
    "    if \"CAM_\" in sensor_name:\n",
    "        blueprint_name = \"sensor.camera.rgb\"\n",
    "        sensor_type = blueprint_name\n",
    "        blueprint = blueprint_library.find(blueprint_name)\n",
    "        sensor_intrinsics = intrinsics.get(sensor_name, dict())\n",
    "\n",
    "        def calculate_fov(focal_length, image_width):\n",
    "            fov_radians = 2 * np.arctan(image_width / (2 * focal_length))\n",
    "            fov_degrees = np.degrees(fov_radians)\n",
    "            return fov_degrees\n",
    "        image_width = str(sensor_intrinsics.get(\"w\", 1600))\n",
    "        blueprint.set_attribute('image_size_x', image_width)\n",
    "        image_height = str(sensor_intrinsics.get(\"h\", 900))\n",
    "        blueprint.set_attribute('image_size_y', image_height)\n",
    "        focal_distance = float(sensor_intrinsics.get(\"fl\"))\n",
    "        field_of_view = str(calculate_fov(focal_distance, float(image_width)))\n",
    "        blueprint.set_attribute('fov', field_of_view)\n",
    "        \n",
    "        transform_matrix = extrinsics.compute_chain_transform(extrinsics.robot.get_chain(extrinsics.root, sensor_name))\n",
    "        transform_matrix = transform_to_carla(\"camera\", transform_matrix)\n",
    "        transform = matrix_to_transform(transform_matrix)\n",
    "        attached_to = vehicle\n",
    "        sensor = world.spawn_actor(blueprint, transform, attach_to=attached_to)\n",
    "        sensors.append(sensor)\n",
    "        sensor_types.append(sensor_type)\n",
    "        sensor_names.append(sensor_name)\n",
    "\n",
    "        ## Spawn additional DEPTH and SEMANTIC cams\n",
    "        blueprint_name = \"sensor.camera.depth\"\n",
    "        sensor_type = blueprint_name\n",
    "        blueprint = blueprint_library.find(blueprint_name)\n",
    "        blueprint.set_attribute('image_size_x', image_width)\n",
    "        blueprint.set_attribute('image_size_y', image_height)\n",
    "        blueprint.set_attribute('fov', field_of_view)\n",
    "        attached_to = vehicle\n",
    "        sensor = world.spawn_actor(blueprint, transform, attach_to=attached_to)\n",
    "        sensors.append(sensor)\n",
    "        sensor_types.append(sensor_type)\n",
    "        sensor_names.append(f\"DEPTH_{sensor_name}\")\n",
    "\n",
    "        blueprint_name = \"sensor.camera.semantic_segmentation\"\n",
    "        sensor_type = blueprint_name\n",
    "        blueprint = blueprint_library.find(blueprint_name)\n",
    "        blueprint.set_attribute('image_size_x', image_width)\n",
    "        blueprint.set_attribute('image_size_y', image_height)\n",
    "        blueprint.set_attribute('fov', field_of_view)\n",
    "        attached_to = vehicle\n",
    "        sensor = world.spawn_actor(blueprint, transform, attach_to=attached_to)\n",
    "        sensors.append(sensor)\n",
    "        sensor_types.append(sensor_type)\n",
    "        sensor_names.append(f\"SEMANTIC_{sensor_name}\")\n",
    "\n",
    "    elif \"RADAR_\" in sensor_name:\n",
    "        blueprint_name = \"sensor.other.radar\"\n",
    "        sensor_type = blueprint_name\n",
    "        blueprint = blueprint_library.find(blueprint_name)     \n",
    "        blueprint.set_attribute('horizontal_fov', str(30.0)) \n",
    "        blueprint.set_attribute('vertical_fov', str(30.0)) \n",
    "        blueprint.set_attribute('points_per_second', str(1e5))\n",
    "        \n",
    "        transform_matrix = extrinsics.get_T_from_to(\"center\", sensor_name)\n",
    "        transform_matrix = transform_to_carla('radar', transform_matrix)\n",
    "        transform = matrix_to_transform(transform_matrix)\n",
    "        attached_to = vehicle\n",
    "        sensor = world.spawn_actor(blueprint, transform, attach_to=attached_to)\n",
    "        sensors.append(sensor)\n",
    "        sensor_types.append(sensor_type)\n",
    "        sensor_names.append(sensor_name)\n",
    "\n",
    "    elif \"LIDAR_\" in sensor_name:\n",
    "        blueprint_name = \"sensor.lidar.ray_cast_semantic\"\n",
    "        sensor_type = blueprint_name\n",
    "        blueprint = blueprint_library.find(blueprint_name)\n",
    "        blueprint.set_attribute(\"channels\", str(64))\n",
    "        blueprint.set_attribute(\"points_per_second\", str(112000))\n",
    "        blueprint.set_attribute(\"range\", str(100))\n",
    "        \n",
    "        transform_matrix = extrinsics.get_T_from_to(\"center\", sensor_name)\n",
    "        transform_matrix = transform_to_carla('lidar', transform_matrix)\n",
    "        transform = matrix_to_transform(transform_matrix)\n",
    "        attached_to = vehicle\n",
    "        sensor = world.spawn_actor(blueprint, transform, attach_to=attached_to)\n",
    "        sensors.append(sensor)\n",
    "        sensor_types.append(sensor_type)\n",
    "        sensor_names.append(sensor_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of sensors spawned: {len(sensors)}\")\n",
    "print(sensor_names)\n",
    "print(sensor_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add traffic (non-ego vehicles and pedestrians) to simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vehicles_to_simulation(n_vehicles: int=0):\n",
    "    \"\"\"\n",
    "    Choos n_vehicles amount of vehicles from Carla's Blueprint Library and\n",
    "    spawn them at random points on the map. Each of those vehicles are set\n",
    "    on autopilot and controlled by Carla's Traffic Manager.\n",
    "    \n",
    "    NB! If randomly chosen spawn points collide, the vehicle is not spawned\n",
    "    so there might be fewer vehicles than set by n_vehicles.\n",
    "\n",
    "    Inputs:\n",
    "        n_vehicles - amount of vehicles to spawn\n",
    "    \"\"\"\n",
    "    if n_vehicles == 0:\n",
    "        return\n",
    "    \n",
    "    vehicle_blueprints = blueprint_library.filter('vehicle')\n",
    "    \n",
    "    npcs = []\n",
    "    collisions = 0\n",
    "    for _ in range(n_vehicles):\n",
    "        vehicle_bp = random.choice(vehicle_blueprints)\n",
    "        spawn_point = random.choice(spawn_points)\n",
    "        npc = world.try_spawn_actor(vehicle_bp, spawn_point)\n",
    "        if npc:\n",
    "            npcs.append(npc)\n",
    "        else:\n",
    "            collisions += 1\n",
    "    \n",
    "    if collisions:\n",
    "        print(f\"Failed to spawn {collisions}/{n_vehicles} vehicles because of collisions\")\n",
    "    \n",
    "    port = traffic_manager.get_port()\n",
    "    for npc in npcs:\n",
    "        npc.set_autopilot(True, port)\n",
    "\n",
    "def add_pedestrians_to_simulation(n_pedestrians: int=0,\n",
    "                                  min_speed: float=1.0,\n",
    "                                  max_speed: float=2.0) -> None:\n",
    "    \"\"\"\n",
    "    Choose n_pedestrians amount of random pedestrians from Carla's\n",
    "    Blueprint Library, attach them to AI and spawn them to random \n",
    "    positions in the simulation. Set a random location for them to \n",
    "    walk to and speed between min_speed and max_speed for them to\n",
    "    walk at.\n",
    "\n",
    "    NB! If the randomly chosen spawn points collide, a pedestrian\n",
    "    is not spawned, so there might be fewer pedestrians than \n",
    "    n_pedestrians in the simulation.\n",
    "\n",
    "    Inputs:\n",
    "        n_pedestrians - number of pedestrians to spawn\n",
    "        min_speed - minimum walking speed for a pedestrian\n",
    "        max_speed - maximum walking speed for a pedestrian\n",
    "    \"\"\"\n",
    "    if n_pedestrians == 0:\n",
    "        return\n",
    "    \n",
    "    pedestrian_blueprints = blueprint_library.filter(\"walker.pedestrian.*\")\n",
    "    points = []\n",
    "    for i in range(n_pedestrians):\n",
    "        point = carla.Transform()\n",
    "        point.location = world.get_random_location_from_navigation()\n",
    "        if (point.location != None):\n",
    "            points.append(point)\n",
    "    batch = []\n",
    "\n",
    "    # Create a batch of spawn commands\n",
    "    for point in points:\n",
    "        pedestrian_bp = random.choice(pedestrian_blueprints)\n",
    "        batch.append(carla.command.SpawnActor(pedestrian_bp, point))\n",
    "\n",
    "    # Apply the batch of commands\n",
    "    results = client.apply_batch_sync(batch, True)\n",
    "    walkers_list = []\n",
    "    collisions = 0\n",
    "    for i in range(len(results)):\n",
    "        if results[i].error:\n",
    "            collisions += 1\n",
    "        else:\n",
    "            walkers_list.append({\"id\": results[i].actor_id})\n",
    "\n",
    "    if collisions:\n",
    "        print(f\"Failed to spawn {collisions}/{n_pedestrians} pedestrians because of collisions\")\n",
    "\n",
    "    # Create a batch of spawn commands for AI controllers\n",
    "    batch = []\n",
    "    walker_controller_bp = blueprint_library.find('controller.ai.walker')\n",
    "    for i in range(len(walkers_list)):\n",
    "        batch.append(carla.command.SpawnActor(walker_controller_bp, carla.Transform(), walkers_list[i][\"id\"]))\n",
    "\n",
    "    # Apply the batch of commands\n",
    "    results = client.apply_batch_sync(batch, True)\n",
    "    for i in range(len(results)):\n",
    "        if results[i].error:\n",
    "            print(f\"Spawning pedestrian AI failed: {results[i].error}\")\n",
    "        else:\n",
    "            walkers_list[i][\"con\"] = results[i].actor_id\n",
    "\n",
    "    all_ids = []\n",
    "    for i in range(len(walkers_list)):\n",
    "        all_ids.append(walkers_list[i][\"con\"])\n",
    "        all_ids.append(walkers_list[i][\"id\"])\n",
    "    all_actors = world.get_actors(all_ids)\n",
    "\n",
    "    for i in range(0, len(all_actors), 2):\n",
    "        all_actors[i].start()\n",
    "        all_actors[i].go_to_location(world.get_random_location_from_navigation())\n",
    "        all_actors[i].set_max_speed(random.uniform(min_speed, max_speed))\n",
    "\n",
    "add_vehicles_to_simulation(n_vehicles=30)\n",
    "add_pedestrians_to_simulation(n_pedestrians=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run full simulation in CARLA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filesystem methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_all_in_directory(target_directory):\n",
    "    if os.path.exists(target_directory):\n",
    "        for filename in os.listdir(target_directory):\n",
    "            file_path = os.path.join(target_directory, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.remove(file_path) \n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)\n",
    "            except Exception as e:\n",
    "                print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "\n",
    "\n",
    "def create_filename_from_timestamp(timestamp):\n",
    "    SECONDS_TO_NANOSECONDS = 1000000000\n",
    "    filename = str(math.trunc(timestamp * SECONDS_TO_NANOSECONDS))\n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### General sensor processing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sensor_position(raw_data, target_directory, sensor_type=None):\n",
    "    transform_matrix = raw_data.transform.get_matrix()\n",
    "    if sensor_type is not None:\n",
    "        transform_matrix = transform_from_carla(sensor_type, transform_matrix)\n",
    "    if not os.path.exists(target_directory):\n",
    "        os.makedirs(target_directory, exist_ok=True)\n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".npy\"\n",
    "    np.save(f\"{target_directory}/{filename}\", transform_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Camera Methods (RGB, Semantic and Depth) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_camera_image(raw_data, target_directory):    \n",
    "    directory = os.path.dirname(target_directory)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    rgb_image = np.reshape(raw_data.raw_data, (raw_data.height, raw_data.width, 4))[:, :, :3] # Remove alpha channel\n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".png\"\n",
    "    cv2.imwrite(f\"{directory}/{filename}\", rgb_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Radar Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_radar_readings(raw_data, target_directory):\n",
    "    directory = os.path.dirname(target_directory)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    radar_points_list = []\n",
    "    for measurement in raw_data:\n",
    "        azi = math.degrees(measurement.azimuth)\n",
    "        alt = math.degrees(measurement.altitude)\n",
    "        fw_vec = carla.Vector3D(x=measurement.depth)\n",
    "        carla.Transform(\n",
    "            carla.Location(),\n",
    "            carla.Rotation(pitch=alt,yaw=azi,roll=0)\n",
    "        ).transform(fw_vec)\n",
    "        radar_points_list.append([fw_vec.x, fw_vec.y, fw_vec.z])\n",
    "    \n",
    "    points = np.array(radar_points_list)\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(points)\n",
    "    \n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".ply\"\n",
    "    o3d.io.write_point_cloud(f\"{directory}/{filename}\", point_cloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lidar methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_lidar_readings(raw_data, target_directory):\n",
    "    directory = os.path.dirname(target_directory)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".ply\"\n",
    "    raw_data.save_to_disk(f\"{directory}/{filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Semantic Lidar Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_semantic_lidar_readings(raw_data, target_directory):\n",
    "    directory = os.path.dirname(target_directory)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    lidar_data = np.array([(detection.point.x, detection.point.y, detection.point.z, detection.object_tag) for detection in raw_data])\n",
    "    points = lidar_data[:, :3]\n",
    "    semantic_tags = lidar_data[:, 3] \n",
    "    semantic_colors_rgb = np.zeros((len(semantic_tags), 3))\n",
    "    semantic_colors_rgb[:, 0] = semantic_tags\n",
    "    semantic_colors_normalized = semantic_colors_rgb / 255.0\n",
    "    \n",
    "    # Create an Open3D point cloud object\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(points)\n",
    "    point_cloud.colors = o3d.utility.Vector3dVector(semantic_colors_normalized)\n",
    "\n",
    "    # Save the point cloud to a .ply file\n",
    "    filename = create_filename_from_timestamp(raw_data.timestamp) + \".ply\"\n",
    "    o3d.io.write_point_cloud(f\"{target_directory}/{filename}\", point_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMULATED_DATA_DIRECTORY = \"./generated_data\"\n",
    "delete_all_in_directory(SIMULATED_DATA_DIRECTORY)\n",
    "\n",
    "cv2.namedWindow(\"Press Q to stop simulation\")\n",
    "cv2.imshow(\"Press Q to stop simulation\", np.zeros((1,1)))\n",
    "\n",
    "vehicle_control_agent = BasicAgent(vehicle, target_speed=15)\n",
    "agent_path = get_agent_path(planned_path)\n",
    "vehicle_control_agent.set_destination(agent_path.pop(0))\n",
    "\n",
    "try:\n",
    "    with CarlaSyncMode(world, sensors, fps=10) as sync_mode:\n",
    "        print(\"Driving to the start of the path...\")\n",
    "        while vehicle_control_agent.done() is False:\n",
    "            if (cv2.waitKey(1) == ord('q')):\n",
    "                break\n",
    "            simulated_results = sync_mode.tick()[1:]\n",
    "            cam_sensor = simulated_results[0]\n",
    "            cam_sensor_image =  np.reshape(np.copy(cam_sensor.raw_data), (cam_sensor.height, cam_sensor.width, 4))\n",
    "            cv2.imshow(\"CAM_FRONT\", cam_sensor_image)\n",
    "            \n",
    "            vehicle.apply_control(vehicle_control_agent.run_step())\n",
    "        print(\"Arrived at the start of the path!\")\n",
    "\n",
    "        print(\"Driving on path...\")\n",
    "        while True:\n",
    "            simulation_results = sync_mode.tick(timeout=100.0)[1:]\n",
    "            for i in range(len(simulation_results)):\n",
    "                sensor = sensors[i]\n",
    "                sensor_data = simulation_results[i]\n",
    "                sensor_name = sensor_names[i].replace(\"base_link_to_\", \"\")\n",
    "                sensor_type = sensor_types[i]\n",
    "                if (\"camera.rgb\" in sensor_type):\n",
    "                    save_camera_image(sensor_data, f\"generated_data/{sensor_name}/\")\n",
    "                elif (\"camera.semantic_segmentation\" in sensor_type):\n",
    "                    save_camera_image(sensor_data, f\"generated_data/{sensor_name}/\")\n",
    "                elif (\"sensor.other.radar\" in sensor_type):\n",
    "                    save_radar_readings(sensor_data, f\"generated_data/{sensor_name}/\")\n",
    "                elif (\"camera.depth\" in sensor_type):\n",
    "                    save_camera_image(sensor_data, f\"generated_data/{sensor_name}/\") \n",
    "                elif (\"sensor.lidar.ray_cast_semantic\" in sensor_type):\n",
    "                    save_semantic_lidar_readings(sensor_data, f\"generated_data/{sensor_name}/\")\n",
    "                elif (\"sensor.lidar\" in sensor_type):\n",
    "                    save_lidar_readings(sensor_data, f\"generated_data/{sensor_name}/\")\n",
    "                save_sensor_position(sensor_data, f\"generated_data/{sensor_name}/\", sensor_type=sensor_type)\n",
    "            \n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "\n",
    "            if vehicle_control_agent.done():\n",
    "                print(f\"{datetime.now()} Checkpoint reached. Ego vehicle has reached {len(planned_path) - len(agent_path)}/{len(planned_path)} planned path points.\")\n",
    "                if len(agent_path) == 0:\n",
    "                    break\n",
    "                vehicle_control_agent.set_destination(agent_path.pop(0))\n",
    "            vehicle.apply_control(vehicle_control_agent.run_step())\n",
    "\n",
    "        print(\"Driving on path finished!\")\n",
    "finally:\n",
    "    cv2.destroyAllWindows()\n",
    "    for sensor in sensors:\n",
    "        sensor.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
