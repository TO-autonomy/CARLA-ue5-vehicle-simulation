{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import Delaunay\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "import json\n",
    "import shutil\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "from classes.CARLASemantics import SemanticColors, SemanticTags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Command-line arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the arguments if running from command line or \n",
    "# use default values if running from Jupyter Notebook\n",
    "if 'ipykernel_launcher.py' in sys.argv[0]: \n",
    "    args = argparse.Namespace(\n",
    "        ego_vehicle_extrinsics='/home/leppsalu/Desktop/Github/CARLA-vehicle-simulation/src/config/carla_extrinsics.urdf',\n",
    "        ego_vehicle_intrinsics='/home/leppsalu/Desktop/Github/CARLA-vehicle-simulation/src/config/carla_intrinsics.json',\n",
    "        input_dir='/media/leppsalu/SSD_Storage/generated_data_town02',\n",
    "        output_dir='/media/leppsalu/SSD_Storage/processed_data_town02',\n",
    "        n_frames_per_bag=1800\n",
    "    )\n",
    "else:\n",
    "    # Create the parser\n",
    "    parser = argparse.ArgumentParser(description='Run simulation postprocessing.')\n",
    "    # Add arguments\n",
    "    parser.add_argument('--ego_vehicle_extrinsics', type=str, required=False, default='/home/leppsalu/Desktop/Github/CARLA-vehicle-simulation/src/config/carla_extrinsics.urdf',\n",
    "                        help='Path to the ego vehicle extrinsics file')\n",
    "    parser.add_argument('--ego_vehicle_intrinsics', type=str, required=False, default='/home/leppsalu/Desktop/Github/CARLA-vehicle-simulation/src/config/carla_intrinsics.json',\n",
    "                        help='Path to the ego vehicle intrinsics file')\n",
    "    parser.add_argument('--input_dir', type=str, required=False, default='\"/home/leppsalu/Desktop/Github/CARLA-vehicle-simulation/src/generated_data\"',\n",
    "                        help='Path to the input directory')\n",
    "    parser.add_argument('--output_dir', type=str, required=False, default='\"/home/leppsalu/Desktop/Github/CARLA-vehicle-simulation/src/processed_data\"',\n",
    "                        help='Path to the output directory')\n",
    "    parser.add_argument('--n_frames_per_bag', type=int, required=False, default=1800)\n",
    "    # Parse the arguments\n",
    "    args = parser.parse_args()\n",
    "\n",
    "SOURCE_DIR = args.input_dir\n",
    "TARGET_DIR = args.output_dir \n",
    "EXTRINSICS_FILEPATH = args.ego_vehicle_extrinsics\n",
    "INTRINSICS_FILEPATH = args.ego_vehicle_intrinsics\n",
    "N_FRAMES_PER_BAG = args.n_frames_per_bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIDAR_DIR = \"LIDAR_TOP\"\n",
    "CAM_DIRS = [\"CAM_FRONT\", \"CAM_FRONT_LEFT\", \"CAM_FRONT_RIGHT\", \"CAM_BACK\", \"CAM_BACK_LEFT\", \"CAM_BACK_RIGHT\"]\n",
    "SEMANTIC_CAM_DIRS =  [\"SEMANTIC_CAM_FRONT\", \"SEMANTIC_CAM_FRONT_LEFT\", \"SEMANTIC_CAM_FRONT_RIGHT\", \"SEMANTIC_CAM_BACK\", \"SEMANTIC_CAM_BACK_LEFT\", \"SEMANTIC_CAM_BACK_RIGHT\"]\n",
    "DEPTH_CAM_DIRS = [\"DEPTH_CAM_FRONT\", \"DEPTH_CAM_FRONT_LEFT\", \"DEPTH_CAM_FRONT_RIGHT\", \"DEPTH_CAM_BACK\", \"DEPTH_CAM_BACK_LEFT\", \"DEPTH_CAM_BACK_RIGHT\"]\n",
    "DEPTH_BEV_DIR = \"DEPTH_BEV\"\n",
    "DEPTH_VISIBILITY_DIR = \"DEPTH_VISIBILITY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intrinsics file (list of sensor configurations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(INTRINSICS_FILEPATH, \"r\") as INTRINSICS_FILE:\n",
    "    INTRINSICS = json.load(INTRINSICS_FILE)\n",
    "\n",
    "INTRINSICS_MATRICES = dict()\n",
    "for SENSOR_NAME in INTRINSICS.keys():\n",
    "    if SENSOR_NAME in CAM_DIRS:\n",
    "        CAMERA_INTRINSICS = INTRINSICS[SENSOR_NAME]\n",
    "        fx = CAMERA_INTRINSICS.get('fx', CAMERA_INTRINSICS.get('fl'))\n",
    "        fy = CAMERA_INTRINSICS.get('fy', CAMERA_INTRINSICS.get('fl'))\n",
    "        w, h = CAMERA_INTRINSICS.get('w'), CAMERA_INTRINSICS.get('h')\n",
    "        ppx = w / 2\n",
    "        ppy = h / 2\n",
    "        d_type = CAMERA_INTRINSICS['disto_type']\n",
    "        D = np.array(CAMERA_INTRINSICS['disto'])\n",
    "\n",
    "        INTRINSICS_MATRICES[SENSOR_NAME] = np.array([[fx, 0, ppx, 0],\n",
    "                                                     [0, fy, ppy, 0],\n",
    "                                                     [0, 0, 1, 0]], dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post processing constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID_SIZE = 52\n",
    "GRID_RESOLUTION = 0.5\n",
    "MAX_SENSOR_SCAN_DISTANCE = 52 # meters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filesystem methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_files_in_dir(data_dir, string_to_find):\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if string_to_find in file:\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    os.remove(file_path)\n",
    "                    # print(f\"Removed: {file_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error removing {file_path}: {e}\")\n",
    "\n",
    "def get_all_filenames(dir, no_extension=False):\n",
    "    if no_extension:\n",
    "        return [filename.split(\".\")[0] for filename in os.listdir(dir)]\n",
    "    return [filename for filename in os.listdir(dir)]\n",
    "\n",
    "def clean_up_lidar_dir():\n",
    "    LIDAR_DIR_PATH = os.path.join(SOURCE_DIR, LIDAR_DIR)\n",
    "    remove_files_in_dir(LIDAR_DIR_PATH, \".bev.\")\n",
    "\n",
    "def clean_up_camera_dirs():\n",
    "    for CAM_DIR in CAM_DIRS:\n",
    "        CAM_DIR_PATH = os.path.join(SOURCE_DIR, CAM_DIR)\n",
    "        remove_files_in_dir(CAM_DIR_PATH, \".pointcloud.\")\n",
    "        remove_files_in_dir(CAM_DIR_PATH, \".visibility.\")\n",
    "        remove_files_in_dir(CAM_DIR_PATH, \".fov.\")\n",
    "\n",
    "def clean_up_depth_camera_dirs():\n",
    "    for DEPTH_CAM_DIR in DEPTH_CAM_DIRS:\n",
    "        DEPTH_CAM_DIR_PATH = os.path.join(SOURCE_DIR, DEPTH_CAM_DIR)\n",
    "        remove_files_in_dir(DEPTH_CAM_DIR_PATH, \".ply\")\n",
    "        remove_files_in_dir(DEPTH_CAM_DIR_PATH, \".fov.\")\n",
    "        remove_files_in_dir(DEPTH_CAM_DIR_PATH, \".visibility.\")\n",
    "\n",
    "def clean_up_depth_bev_dir():\n",
    "    DEPTH_BEV_DIR_PATH = os.path.join(SOURCE_DIR, DEPTH_BEV_DIR)\n",
    "    remove_files_in_dir(DEPTH_BEV_DIR_PATH, \".\")\n",
    "\n",
    "def clean_up_depth_visibility_dir():\n",
    "    DEPTH_VISIBILITY_DIR_PATH = os.path.join(SOURCE_DIR, DEPTH_VISIBILITY_DIR)\n",
    "    remove_files_in_dir(DEPTH_VISIBILITY_DIR_PATH, \".\")\n",
    "        \n",
    "def save_point_cloud(file_path, point_cloud):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    if type(point_cloud) is o3d.geometry.PointCloud:\n",
    "        o3d.io.write_point_cloud(file_path, point_cloud)\n",
    "        return\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(point_cloud)\n",
    "    o3d.io.write_point_cloud(file_path, pcd)\n",
    "\n",
    "def read_point_cloud(file_path):\n",
    "    point_cloud = o3d.io.read_point_cloud(file_path)\n",
    "    return np.asarray(point_cloud.points)\n",
    "\n",
    "def save_image(file_path, mask):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    cv2.imwrite(file_path, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground Truth from depth camera point clouds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Depth image parsing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_depth_map_from_image(image):\n",
    "    B = image[:, :, 0]\n",
    "    G = image[:, :, 1]\n",
    "    R = image[:, :, 2]\n",
    "    normalized = (G + B * 256 + R * 256 * 256) / (256 * 256 - 1)\n",
    "    depth_map = normalized * 1000\n",
    "    return depth_map\n",
    "\n",
    "def depth_image_to_point_cloud(depth_image, fov, max_distance=None):\n",
    "    \n",
    "    depth = calculate_depth_map_from_image(depth_image)\n",
    "    if max_distance != None:\n",
    "        depth[depth > max_distance] = 0.0 \n",
    "    height, width = depth_image.shape[:2]\n",
    "\n",
    "    # Create an intrinsic matrix from the camera parameters\n",
    "    fx = fy = 0.5 * width / np.tan(0.5 * np.radians(fov))\n",
    "    cx = width / 2.0\n",
    "    cy = height / 2.0\n",
    "\n",
    "    intrinsic = o3d.camera.PinholeCameraIntrinsic(width, height, fx, fy, cx, cy)\n",
    "\n",
    "    depth_o3d = o3d.geometry.Image(depth.astype(np.float32))\n",
    "    \n",
    "    pcd = o3d.geometry.PointCloud.create_from_depth_image(depth_o3d, intrinsic)\n",
    "    points = np.asarray(pcd.points)\n",
    "    points[:, 0] = -points[:, 0]\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    return pcd\n",
    "\n",
    "def create_color_mask(image, colors, inverted=False):\n",
    "    mask = np.full((image.shape[0], image.shape[1]), 0, dtype=np.uint8)\n",
    "    \n",
    "    B, G, R = image[:, :, 0], image[:, :, 1], image[:, :, 2]\n",
    "    # Iterate through the list of colors\n",
    "    for color in colors:\n",
    "        # Extract color channels\n",
    "        r, g, b = color\n",
    "        # Create boolean masks for each channel comparison\n",
    "        r_mask = R == r\n",
    "        g_mask = G == g\n",
    "        b_mask = B == b\n",
    "        # Combine channel masks to get the final color mask\n",
    "        color_mask = r_mask & g_mask & b_mask\n",
    "        # Update the overall mask where any color matches\n",
    "        mask[color_mask] = 255\n",
    "\n",
    "    if inverted:\n",
    "        mask = np.where(mask == 0, 255, 0).astype(np.uint8)\n",
    "        return mask\n",
    "    return mask\n",
    "\n",
    "def mask_image(image, image_mask):\n",
    "    masked = np.copy(image)\n",
    "    masked[image_mask == 0] = 0\n",
    "    return masked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods for creating FOV masks, visibility masks and BEV maps from depth images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mask(grid, camera_matrix, T, image_size):\n",
    "    homogeneous_grid = np.vstack([grid[i].flatten() for i in range(3)] + [np.ones(grid[0].size)])\n",
    "    tfd_points = np.dot(T, homogeneous_grid)\n",
    "    tfd_points = np.dot(camera_matrix, tfd_points)\n",
    "    mask_z = tfd_points[2] > 0 # Exclude points behind the camera\n",
    "    tfd_points[2][tfd_points[2] == 0] = np.nan  # Replace zeros with NaN to avoid division by zero\n",
    "    projected_points = tfd_points / tfd_points[2]\n",
    "    mask = ((0 <= projected_points[0]) & (projected_points[0] < image_size[0]) &\n",
    "            (0 <= projected_points[1]) & (projected_points[1] < image_size[1]) &\n",
    "            mask_z)\n",
    "    return mask.reshape(grid[0].shape)\n",
    "\n",
    "def get_camera_fov_masks(camera_calibs, lidar_to_cam_tf_list=[], grid_size_m=50, resolution=0.5):\n",
    "    whole_mask = np.zeros((int(grid_size_m / resolution), int(grid_size_m / resolution)))\n",
    "    x, y = np.meshgrid(np.arange(whole_mask.shape[1]), np.arange(whole_mask.shape[0]))\n",
    "    x = x - whole_mask.shape[1] / 2\n",
    "    y = y - whole_mask.shape[0] / 2\n",
    "    z = np.zeros_like(x)\n",
    "    bev_grid = np.array([x, y, z])\n",
    "    bev_grid = np.expand_dims(bev_grid, axis=-1)\n",
    "\n",
    "    cam_masks = {}\n",
    "\n",
    "    for i, (camera, calib) in enumerate(camera_calibs.items()):\n",
    "        intrinsic = calib['K']\n",
    "\n",
    "        w, h = calib['w'], calib['h']\n",
    "\n",
    "        if lidar_to_cam_tf_list:\n",
    "            cam_T_lidar = np.linalg.inv(lidar_to_cam_tf_list[i])\n",
    "        else:\n",
    "            cam_T_lidar = np.linalg.inv(calib['T'])\n",
    "\n",
    "        mask = generate_mask(bev_grid, camera_matrix=intrinsic, T=cam_T_lidar, image_size=(w, h))\n",
    "        visible_bev = np.array([dim[mask] for dim in bev_grid])\n",
    "\n",
    "        mask_ref = visible_bev[:2]\n",
    "        cam_mask = np.zeros_like(mask)\n",
    "\n",
    "        mask_ref[1] += mask.shape[1] / 2\n",
    "        mask_ref[0] += mask.shape[0] / 2\n",
    "        mask_ref = np.round(mask_ref).astype(int)\n",
    "\n",
    "        cam_mask[mask_ref[1], mask_ref[0]] = 1\n",
    "        cam_mask = cam_mask.squeeze(-1)\n",
    "\n",
    "        cam_masks[camera] = cam_mask\n",
    "    return cam_masks\n",
    "\n",
    "def get_fov_mask(image, transformation_matrix, camera_intrinsics_matrix):\n",
    "    # Example camera calibration data for two cameras\n",
    "    camera_calibs = {\n",
    "        'camera': {\n",
    "            'K': camera_intrinsics_matrix,\n",
    "            'w': image.shape[1],  # Image width\n",
    "            'h': image.shape[0],  # Image height\n",
    "            'T': transformation_matrix\n",
    "        }\n",
    "    }\n",
    "    # Generate the camera FOV masks\n",
    "    cam_masks = get_camera_fov_masks(camera_calibs, grid_size_m=GRID_SIZE, resolution=GRID_RESOLUTION)\n",
    "    fov_mask = np.asarray(cam_masks[\"camera\"], dtype=np.uint8) * 255\n",
    "    \n",
    "    return fov_mask\n",
    "\n",
    "def calculate_fov(focal_length, image_width):\n",
    "    fov_radians = 2 * np.arctan(image_width / (2 * focal_length))\n",
    "    fov_degrees = np.degrees(fov_radians)\n",
    "    return fov_degrees\n",
    "\n",
    "def rasterize_to_bev(points, resolution=0.5, grid_size=25):\n",
    "    bev_map = np.zeros((int(grid_size / resolution), int(grid_size / resolution)))\n",
    "    # Converting to grid coordinates\n",
    "    grid_coords = np.floor(points[:, :2] / resolution).astype(np.int32) + int(grid_size // (2 * resolution))\n",
    "    \n",
    "    # Ensure that grid coordinates are within the bounds of the BEV map\n",
    "    valid_points = (grid_coords[:, 0] >= 0) & (grid_coords[:, 0] < bev_map.shape[0]) & \\\n",
    "                   (grid_coords[:, 1] >= 0) & (grid_coords[:, 1] < bev_map.shape[1])\n",
    "    # Populate the BEV map with occupancy\n",
    "    bev_map[grid_coords[valid_points, 0], grid_coords[valid_points, 1]] = 255\n",
    "    return bev_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create point clouds, FOV masks, visibility masks and occupancy maps from depth images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_filenames(dir, no_extension=False):\n",
    "    if no_extension:\n",
    "        return [filename.split(\".\")[0] for filename in os.listdir(dir)]\n",
    "    return [filename for filename in os.listdir(dir)]\n",
    "\n",
    "def get_obstacle_point_cloud(depth_image, semantic_image, fov):\n",
    "    obstacles_mask = create_color_mask(\n",
    "        semantic_image, \n",
    "        colors=[\n",
    "            SemanticColors.ROADLINE.value, SemanticColors.ROAD.value, SemanticColors.SIDEWALK.value,\n",
    "            SemanticColors.GROUND.value, SemanticColors.WATER.value, SemanticColors.TERRAIN.value,\n",
    "            SemanticColors.SKY.value\n",
    "        ],\n",
    "        inverted=True\n",
    "    )\n",
    "    obstacles_depth_image = mask_image(depth_image, obstacles_mask)\n",
    "    obstacles_point_cloud = depth_image_to_point_cloud(obstacles_depth_image, fov=fov, max_distance=MAX_SENSOR_SCAN_DISTANCE)\n",
    "    return obstacles_point_cloud\n",
    "\n",
    "def get_ground_point_cloud(depth_image, semantic_image, fov):\n",
    "    ground_mask = create_color_mask(semantic_image, colors=[\n",
    "        SemanticColors.ROADLINE.value, SemanticColors.ROAD.value, SemanticColors.SIDEWALK.value,\n",
    "        SemanticColors.GROUND.value, SemanticColors.WATER.value, SemanticColors.TERRAIN.value\n",
    "    ])\n",
    "    ground_depth_image = mask_image(depth_image, ground_mask)\n",
    "    ground_point_cloud = depth_image_to_point_cloud(ground_depth_image, fov=fov, max_distance=MAX_SENSOR_SCAN_DISTANCE)\n",
    "    return ground_point_cloud\n",
    "\n",
    "def get_corrected_obstacle_point_cloud(obstacles_point_cloud, ground_point_cloud):\n",
    "    def gen_mesh(pcd): \n",
    "        try:\n",
    "            points = np.asarray(pcd.points)\n",
    "        except:\n",
    "            points = pcd\n",
    "        tri = Delaunay(points[:, :2])  # We only use the X and Y coordinates\n",
    "        mesh = o3d.geometry.TriangleMesh()\n",
    "        mesh.vertices = o3d.utility.Vector3dVector(points)\n",
    "        mesh.triangles = o3d.utility.Vector3iVector(tri.simplices)\n",
    "        return mesh\n",
    "    \n",
    "    def mesh_to_cloud_signed_distances(o3d_mesh: o3d.t.geometry.TriangleMesh, cloud: o3d.t.geometry.PointCloud) -> np.ndarray:\n",
    "        scene = o3d.t.geometry.RaycastingScene()\n",
    "        _ = scene.add_triangles(o3d_mesh)\n",
    "        sdf = scene.compute_signed_distance(cloud.point.positions)\n",
    "        return sdf.numpy()\n",
    "\n",
    "    def filter_points_far_from_mesh(pcd, distances, t1, t2):\n",
    "        indices1 = np.where((distances > t1) & (distances <= t2))[0]\n",
    "        indices2 = np.where(distances < t1)[0]\n",
    "        objects = pcd.select_by_index(indices1)\n",
    "        ground = pcd.select_by_index(indices2)\n",
    "        return objects, ground\n",
    "\n",
    "    def remove_points_far_from_mesh(pcd, mesh, height_range=(0.4, 2)):\n",
    "        mesh_t = o3d.t.geometry.TriangleMesh.from_legacy(mesh)\n",
    "        tpcd = o3d.t.geometry.PointCloud.from_legacy(pcd)\n",
    "        sdf = mesh_to_cloud_signed_distances(mesh_t, tpcd)\n",
    "        sdf = np.abs(sdf)\n",
    "        obstacles, ground = filter_points_far_from_mesh(pcd, sdf, *height_range)\n",
    "        return obstacles, ground\n",
    "    try:\n",
    "        ground_mesh = gen_mesh(ground_point_cloud)\n",
    "        obstacles_point_cloud, ground_point_cloud = remove_points_far_from_mesh(obstacles_point_cloud, ground_mesh, height_range=(0.2, 3))\n",
    "    except:\n",
    "        pass\n",
    "    return obstacles_point_cloud\n",
    "\n",
    "clean_up_depth_camera_dirs()\n",
    "clean_up_depth_bev_dir()\n",
    "clean_up_depth_visibility_dir()\n",
    "\n",
    "all_timestamps = get_all_filenames(os.path.join(SOURCE_DIR, DEPTH_CAM_DIRS[0]), no_extension=True)\n",
    "unique_timestamps = set(all_timestamps)\n",
    "\n",
    "print(f\"Post-processing simulation data ...\")\n",
    "for i, timestamp in enumerate(unique_timestamps):\n",
    "    cumulative_obstacle_point_cloud = o3d.geometry.PointCloud()\n",
    "    cumulative_ground_point_cloud = o3d.geometry.PointCloud()\n",
    "    \n",
    "    for (SEM_DIR, DEPTH_DIR, CAM_DIR) in zip(SEMANTIC_CAM_DIRS, DEPTH_CAM_DIRS, CAM_DIRS):\n",
    "        depth_camera_transform_path = os.path.join(SOURCE_DIR, DEPTH_DIR, f\"{timestamp}.npy\")\n",
    "        depth_camera_transform = np.load(depth_camera_transform_path)\n",
    "        \n",
    "        depth_image_path = os.path.join(SOURCE_DIR, DEPTH_DIR, f\"{timestamp}.png\")\n",
    "        depth_image = cv2.imread(depth_image_path)\n",
    "        \n",
    "        image_width = float(INTRINSICS.get(CAM_DIR).get(\"w\"))\n",
    "        focal_length = float(INTRINSICS.get(CAM_DIR).get(\"fl\"))\n",
    "        depth_camera_fov = calculate_fov(focal_length, image_width)\n",
    "        \n",
    "        semantic_image_path = os.path.join(SOURCE_DIR, SEM_DIR, f\"{timestamp}.png\")\n",
    "        semantic_image = cv2.imread(semantic_image_path)\n",
    "        \n",
    "        obstacle_point_cloud = get_obstacle_point_cloud(depth_image, semantic_image, depth_camera_fov)\n",
    "        obstacle_point_cloud.transform(depth_camera_transform)\n",
    "        cumulative_obstacle_point_cloud.points.extend(obstacle_point_cloud.points)\n",
    "        \n",
    "        ground_point_cloud = get_ground_point_cloud(depth_image, semantic_image, depth_camera_fov)\n",
    "        ground_point_cloud.transform(depth_camera_transform)\n",
    "        cumulative_ground_point_cloud.points.extend(ground_point_cloud.points)\n",
    "\n",
    "    cumulative_ground_point_cloud = cumulative_ground_point_cloud.voxel_down_sample(0.25) \n",
    "    cumulative_obstacle_point_cloud = get_corrected_obstacle_point_cloud(cumulative_obstacle_point_cloud, cumulative_ground_point_cloud)\n",
    "    \n",
    "    lidar_transform = np.load(os.path.join(SOURCE_DIR, LIDAR_DIR, f\"{timestamp}.npy\"))\n",
    "    cumulative_obstacle_point_cloud.transform(np.linalg.inv(lidar_transform))\n",
    "    \n",
    "    obstacles_point_cloud_file_path = os.path.join(SOURCE_DIR, DEPTH_BEV_DIR, f\"{timestamp}.ply\")\n",
    "    save_point_cloud(obstacles_point_cloud_file_path, cumulative_obstacle_point_cloud)\n",
    "    # print(f\"Added: {obstacles_point_cloud_file_path}\")\n",
    "    \n",
    "    cumulative_ground_point_cloud.transform(np.linalg.inv(lidar_transform))\n",
    "    ground_point_cloud_file_path = os.path.join(SOURCE_DIR, DEPTH_BEV_DIR, f\"{timestamp}.ground.ply\")\n",
    "    save_point_cloud(ground_point_cloud_file_path, cumulative_ground_point_cloud)\n",
    "    # print(f\"Added: {ground_point_cloud_file_path}\")\n",
    "\n",
    "    occupancy_image = rasterize_to_bev(np.asarray(cumulative_obstacle_point_cloud.points), resolution=GRID_RESOLUTION, grid_size=GRID_SIZE)\n",
    "    occupancy_image_path = os.path.join(SOURCE_DIR, DEPTH_BEV_DIR, f\"{timestamp}.bev.png\")\n",
    "    save_image(occupancy_image_path, occupancy_image)\n",
    "    # print(f\"Added: {occupancy_image_path}\")\n",
    "\n",
    "    def get_signed_distance_field_from_occupancy_image(occupancy_image):\n",
    "        img = np.array(occupancy_image)\n",
    "        inv_arr = (255 - np.array(img))\n",
    "        sdf = distance_transform_edt(inv_arr).astype(np.float32)\n",
    "        sdf += 1\n",
    "        sdf = 1 / sdf \n",
    "        return sdf\n",
    "    \n",
    "    def get_sdf_as_image(sdf_array):\n",
    "        sdf_array = (sdf_array / sdf_array.max() * 255).astype(np.uint8)\n",
    "        sdf_image = cv2.applyColorMap(sdf_array, cv2.COLORMAP_JET)\n",
    "        return sdf_image\n",
    "\n",
    "    sdf = get_signed_distance_field_from_occupancy_image(occupancy_image)\n",
    "    sdf_path = os.path.join(SOURCE_DIR, DEPTH_BEV_DIR, f\"{timestamp}.sdf.npy\")\n",
    "    np.save(sdf_path, sdf)\n",
    "    # print(f\"Added: {sdf_path}\")\n",
    "    sdf_image = get_sdf_as_image(sdf)\n",
    "    sdf_image_path = os.path.join(SOURCE_DIR, DEPTH_BEV_DIR, f\"{timestamp}.sdf.png\")\n",
    "    save_image(sdf_image_path, sdf_image)\n",
    "    # print(f\"Added: {sdf_image_path}\")\n",
    "\n",
    "\n",
    "    transform_file_path = os.path.join(SOURCE_DIR, DEPTH_BEV_DIR, f\"{timestamp}.npy\")\n",
    "    np.save(transform_file_path, lidar_transform)\n",
    "    # print(f\"Added: {transform_file_path}\")\n",
    "\n",
    "    visible_point_cloud = cumulative_ground_point_cloud + cumulative_obstacle_point_cloud\n",
    "    cumulative_visibility_mask = rasterize_to_bev(np.asarray(visible_point_cloud.points), resolution=GRID_RESOLUTION, grid_size=GRID_SIZE).T\n",
    "    cumulative_visibility_mask_path = os.path.join(SOURCE_DIR, DEPTH_VISIBILITY_DIR, f\"{timestamp}.png\")\n",
    "    save_image(cumulative_visibility_mask_path, cumulative_visibility_mask)\n",
    "    # print(f\"Added: {cumulative_visibility_mask_path}\")\n",
    "\n",
    "    transform_file_path = os.path.join(SOURCE_DIR, DEPTH_VISIBILITY_DIR, f\"{timestamp}.npy\")\n",
    "    np.save(transform_file_path, lidar_transform)\n",
    "    # print(f\"Added: {transform_file_path}\")\n",
    "\n",
    "    for CAM_DIR, DEPTH_DIR in zip(CAM_DIRS, DEPTH_CAM_DIRS):\n",
    "        depth_image_path = os.path.join(SOURCE_DIR, DEPTH_DIR, f\"{timestamp}.png\")\n",
    "        depth_image = cv2.imread(depth_image_path)\n",
    "        \n",
    "        depth_camera_transform_path = os.path.join(SOURCE_DIR, DEPTH_DIR, f\"{timestamp}.npy\")\n",
    "        depth_camera_transform = np.load(depth_camera_transform_path)\n",
    "        \n",
    "        lidar_transform_path = os.path.join(SOURCE_DIR, LIDAR_DIR, f\"{timestamp}.npy\")\n",
    "        lidar_transform = np.load(lidar_transform_path)\n",
    "        lidar_transform_inv = np.linalg.inv(lidar_transform)\n",
    "        combined_transform = np.dot(lidar_transform_inv, depth_camera_transform)\n",
    "        \n",
    "        camera_fov_mask = get_fov_mask(depth_image, combined_transform, INTRINSICS_MATRICES[CAM_DIR])\n",
    "        fov_mask_path = os.path.join(SOURCE_DIR, DEPTH_DIR, f\"{timestamp}.fov.png\")\n",
    "        save_image(fov_mask_path, camera_fov_mask)\n",
    "        # print(f\"Added: {fov_mask_path}\")\n",
    "\n",
    "        camera_visibility_mask = np.array((cumulative_visibility_mask > 0) & (camera_fov_mask > 0), dtype=np.uint8) * 255\n",
    "        visibility_mask_path = os.path.join(SOURCE_DIR, DEPTH_DIR, f\"{timestamp}.visibility.png\")\n",
    "        save_image(visibility_mask_path, camera_visibility_mask)\n",
    "        # print(f\"Added: {visibility_mask_path}\")\n",
    "\n",
    "    def get_lidar_obstacle_point_cloud(semantic_point_cloud):\n",
    "        # Extract colors from the point cloud\n",
    "        semantic_colors = np.asarray(semantic_point_cloud.colors)\n",
    "        r_channel = semantic_colors[:, 0] * 255\n",
    "        mask = np.isin(\n",
    "            r_channel, \n",
    "            [ \n",
    "                SemanticTags.ROADLINE.value, SemanticTags.ROAD.value, SemanticTags.SIDEWALK.value,\n",
    "                SemanticTags.GROUND.value, SemanticTags.WATER.value, SemanticTags.TERRAIN.value, \n",
    "                SemanticTags.SKY.value\n",
    "            ],\n",
    "            invert=True\n",
    "        )\n",
    "        # Filter the points and colors based on the mask\n",
    "        filtered_points = np.asarray(semantic_point_cloud.points)[mask]\n",
    "        filtered_colors = semantic_colors[mask]\n",
    "        # Create a new point cloud with the filtered points and colors\n",
    "        filtered_point_cloud = o3d.geometry.PointCloud()\n",
    "        filtered_point_cloud.points = o3d.utility.Vector3dVector(filtered_points)\n",
    "        filtered_point_cloud.colors = o3d.utility.Vector3dVector(filtered_colors)\n",
    "        return filtered_point_cloud\n",
    "    \n",
    "    def get_lidar_ground_point_cloud(semantic_point_cloud):\n",
    "        # Extract colors from the point cloud\n",
    "        semantic_colors = np.asarray(semantic_point_cloud.colors)\n",
    "        r_channel = semantic_colors[:, 0] * 255\n",
    "        mask = np.isin(\n",
    "            r_channel, \n",
    "            [\n",
    "                SemanticTags.ROADLINE.value, SemanticTags.ROAD.value, SemanticTags.SIDEWALK.value,\n",
    "                SemanticTags.GROUND.value, SemanticTags.WATER.value, SemanticTags.TERRAIN.value\n",
    "            ]\n",
    "        )\n",
    "        # Filter the points and colors based on the mask\n",
    "        filtered_points = np.asarray(semantic_point_cloud.points)[mask]\n",
    "        filtered_colors = semantic_colors[mask]\n",
    "        # Create a new point cloud with the filtered points and colors\n",
    "        filtered_point_cloud = o3d.geometry.PointCloud()\n",
    "        filtered_point_cloud.points = o3d.utility.Vector3dVector(filtered_points)\n",
    "        filtered_point_cloud.colors = o3d.utility.Vector3dVector(filtered_colors)\n",
    "        return filtered_point_cloud\n",
    "    \n",
    "    \n",
    "    lidar_point_cloud_path = os.path.join(SOURCE_DIR, LIDAR_DIR, f\"{timestamp}.ply\")\n",
    "    lidar_point_cloud = o3d.io.read_point_cloud(lidar_point_cloud_path)\n",
    "    lidar_ground_point_cloud = get_lidar_ground_point_cloud(lidar_point_cloud)\n",
    "    lidar_ground_point_cloud_path = os.path.join(SOURCE_DIR, LIDAR_DIR, f\"{timestamp}.ground.ply\")\n",
    "    save_point_cloud(lidar_ground_point_cloud_path, lidar_ground_point_cloud)\n",
    "    # print(f\"Added: {lidar_ground_point_cloud_path}\")\n",
    "    \n",
    "    lidar_obstacle_point_cloud = get_lidar_obstacle_point_cloud(lidar_point_cloud)\n",
    "    lidar_obstacle_point_cloud = get_corrected_obstacle_point_cloud(lidar_obstacle_point_cloud, lidar_ground_point_cloud)\n",
    "    lidar_obstacle_point_cloud_path = os.path.join(SOURCE_DIR, LIDAR_DIR, f\"{timestamp}.obstacles.ply\")\n",
    "\n",
    "    lidar_bev_image = rasterize_to_bev(np.asarray(lidar_obstacle_point_cloud.points), resolution=GRID_RESOLUTION, grid_size=GRID_SIZE)\n",
    "    lidar_bev_image_path = os.path.join(SOURCE_DIR, LIDAR_DIR, f\"{timestamp}.bev.png\")\n",
    "    save_image(lidar_bev_image_path, lidar_bev_image)\n",
    "    # print(f\"Added: {lidar_bev_image_path}\")\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Processed {((i+1) / len(unique_timestamps) * 100):.6f}% of frames in the dataset\")\n",
    "print(f\"Processed {((i+1) / len(unique_timestamps) * 100):.6f}% of frames in the dataset\")\n",
    "print(f\"Processed data in {SOURCE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export processed files to target directory (in suitable directory tree format for machine learning pipeline) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_CAM_DIRS = [\"CAM_FRONT\", \"CAM_FRONT_LEFT\", \"CAM_FRONT_RIGHT\", \"CAM_BACK\", \"CAM_BACK_LEFT\", \"CAM_BACK_RIGHT\"]\n",
    "TARGET_LIDAR_DIR = \"LIDAR_TOP\"\n",
    "TARGET_FOV_MASKS_DIR = \"fov_masks\"\n",
    "TARGET_BEVS_DIR = \"bevs\"\n",
    "TARGET_SDFS_DIR = \"sdfs\"\n",
    "TARGET_VISIBILITY_MASKS_DIR = \"visibility_masks\"\n",
    "TARGET_CUMULATIVE_MASKS_DIR = \"cumulative_masks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_target_dir():\n",
    "    if not os.path.exists(TARGET_DIR):\n",
    "        return\n",
    "    for subdir in os.listdir(TARGET_DIR):\n",
    "        shutil.rmtree(os.path.join(TARGET_DIR, subdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_file_to_target_dir(source_file_path, target_file_path):\n",
    "    target_directory_path = os.path.dirname(target_file_path)\n",
    "    os.makedirs(target_directory_path, exist_ok=True)\n",
    "    shutil.copyfile(source_file_path, target_file_path)\n",
    "\n",
    "clean_up_target_dir()\n",
    "\n",
    "all_timestamps = get_all_filenames(os.path.join(SOURCE_DIR, DEPTH_CAM_DIRS[0]), no_extension=True)\n",
    "unique_timestamps = set(all_timestamps)\n",
    "sorted_timestamps = sorted(unique_timestamps, key=int)\n",
    "\n",
    "print(f\"Exporting post-processed data...\")\n",
    "for i, timestamp in enumerate(sorted_timestamps):\n",
    "    if (i % N_FRAMES_PER_BAG) == 0:\n",
    "        start_timestamp = sorted_timestamps[i]\n",
    "        end_timestamp = sorted_timestamps[-1] if (i+N_FRAMES_PER_BAG-1) >= len(sorted_timestamps) else sorted_timestamps[i+N_FRAMES_PER_BAG-1]\n",
    "        TARGET_DIRNAME = os.path.basename(TARGET_DIR)\n",
    "        TARGET_BAG_DIR = f\"{TARGET_DIRNAME}_frames_{start_timestamp}_{end_timestamp}\"\n",
    "    \n",
    "    for CAM_DIR in CAM_DIRS:\n",
    "        source_file_path = os.path.join(SOURCE_DIR, CAM_DIR, f\"{timestamp}.png\")\n",
    "        target_file_path = os.path.join(TARGET_DIR, TARGET_BAG_DIR, CAM_DIR, f\"{timestamp}.png\")\n",
    "        copy_file_to_target_dir(source_file_path, target_file_path)\n",
    "        source_file_path = os.path.join(SOURCE_DIR, CAM_DIR, f\"{timestamp}.npy\")\n",
    "        target_file_path = os.path.join(TARGET_DIR, TARGET_BAG_DIR, CAM_DIR, f\"{timestamp}.npy\")\n",
    "        copy_file_to_target_dir(source_file_path, target_file_path)\n",
    "\n",
    "    source_file_path = os.path.join(SOURCE_DIR, LIDAR_DIR, f\"{timestamp}.ply\")\n",
    "    target_file_path = os.path.join(TARGET_DIR, TARGET_BAG_DIR, LIDAR_DIR, f\"{timestamp}.ply\")\n",
    "    copy_file_to_target_dir(source_file_path, target_file_path)\n",
    "    source_file_path = os.path.join(SOURCE_DIR, LIDAR_DIR, f\"{timestamp}.npy\")\n",
    "    target_file_path = os.path.join(TARGET_DIR, TARGET_BAG_DIR, LIDAR_DIR, f\"{timestamp}.npy\")\n",
    "    copy_file_to_target_dir(source_file_path, target_file_path)\n",
    "\n",
    "    for CAM_DIR, DEPTH_CAM_DIR in zip(CAM_DIRS, DEPTH_CAM_DIRS):\n",
    "        source_file_path = os.path.join(SOURCE_DIR, DEPTH_CAM_DIR, f\"{timestamp}.fov.png\")\n",
    "        target_file_path = os.path.join(TARGET_DIR, TARGET_BAG_DIR, TARGET_FOV_MASKS_DIR, CAM_DIR, f\"{timestamp}.png\")\n",
    "        copy_file_to_target_dir(source_file_path, target_file_path)\n",
    "        source_file_path = os.path.join(SOURCE_DIR, DEPTH_CAM_DIR, f\"{timestamp}.npy\")\n",
    "        target_file_path = os.path.join(TARGET_DIR, TARGET_BAG_DIR, TARGET_FOV_MASKS_DIR, CAM_DIR, f\"{timestamp}.npy\")\n",
    "        copy_file_to_target_dir(source_file_path, target_file_path)\n",
    "\n",
    "        source_file_path = os.path.join(SOURCE_DIR, DEPTH_CAM_DIR, f\"{timestamp}.visibility.png\")\n",
    "        target_file_path = os.path.join(TARGET_DIR, TARGET_BAG_DIR, TARGET_VISIBILITY_MASKS_DIR, CAM_DIR, f\"{timestamp}.png\")\n",
    "        copy_file_to_target_dir(source_file_path, target_file_path)\n",
    "        source_file_path = os.path.join(SOURCE_DIR, DEPTH_CAM_DIR, f\"{timestamp}.npy\")\n",
    "        target_file_path = os.path.join(TARGET_DIR, TARGET_BAG_DIR, TARGET_VISIBILITY_MASKS_DIR, CAM_DIR, f\"{timestamp}.npy\")\n",
    "        copy_file_to_target_dir(source_file_path, target_file_path)\n",
    "\n",
    "    source_file_path = os.path.join(SOURCE_DIR, DEPTH_BEV_DIR, f\"{timestamp}.bev.png\")\n",
    "    target_file_path = os.path.join(TARGET_DIR, TARGET_BAG_DIR, TARGET_BEVS_DIR, f\"{timestamp}.png\")\n",
    "    copy_file_to_target_dir(source_file_path, target_file_path)\n",
    "\n",
    "    source_file_path = os.path.join(SOURCE_DIR, DEPTH_BEV_DIR, f\"{timestamp}.sdf.npy\")\n",
    "    target_file_path = os.path.join(TARGET_DIR, TARGET_BAG_DIR, TARGET_SDFS_DIR, f\"{timestamp}.npy\")\n",
    "    copy_file_to_target_dir(source_file_path, target_file_path)\n",
    "    source_file_path = os.path.join(SOURCE_DIR, DEPTH_BEV_DIR, f\"{timestamp}.sdf.png\")\n",
    "    target_file_path = os.path.join(TARGET_DIR, TARGET_BAG_DIR, TARGET_SDFS_DIR, f\"{timestamp}.png\")\n",
    "    copy_file_to_target_dir(source_file_path, target_file_path)\n",
    "\n",
    "    source_file_path = os.path.join(SOURCE_DIR, DEPTH_VISIBILITY_DIR, f\"{timestamp}.png\")\n",
    "    target_file_path = os.path.join(TARGET_DIR, TARGET_BAG_DIR, TARGET_VISIBILITY_MASKS_DIR, TARGET_CUMULATIVE_MASKS_DIR, f\"{timestamp}.png\")\n",
    "    copy_file_to_target_dir(source_file_path, target_file_path)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Exported {((i+1) / len(unique_timestamps) * 100):.6f}% of frames in the dataset\")\n",
    "\n",
    "print(f\"Exported {((i+1) / len(unique_timestamps) * 100):.6f}% of frames in the dataset\")\n",
    "print(f\"Exported post-processed data to {TARGET_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Post-processing completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
