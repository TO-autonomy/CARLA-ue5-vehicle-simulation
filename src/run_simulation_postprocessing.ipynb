{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import Delaunay\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "import json\n",
    "import shutil\n",
    "import argparse\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "from classes.CARLASemantics import SemanticTags, SemanticColors\n",
    "from classes.util.URDFParser import URDFParser\n",
    "from classes.util.Viewshed3D import ViewShed3D, compute_camera_matrix_4x4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Command-line arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the arguments if running from command line or \n",
    "# use default values if running from Jupyter Notebook\n",
    "if 'ipykernel_launcher.py' in sys.argv[0]: \n",
    "    args = argparse.Namespace(\n",
    "        ego_vehicle_extrinsics='/home/leppsalu/Desktop/Github/CARLA-vehicle-simulation/src/config/carla_extrinsics.urdf',\n",
    "        ego_vehicle_intrinsics='/home/leppsalu/Desktop/Github/CARLA-vehicle-simulation/src/config/carla_intrinsics.json',\n",
    "        input_dir='/home/leppsalu/Desktop/Github/CARLA-vehicle-simulation/src/generated_data_town02-discardable_sample',\n",
    "        output_dir='/home/leppsalu/Desktop/Github/CARLA-vehicle-simulation/src/processed_data_town02-discardable_sample',\n",
    "        n_frames_per_bag=1800\n",
    "    )\n",
    "else:\n",
    "    # Create the parser\n",
    "    parser = argparse.ArgumentParser(description='Run simulation postprocessing.')\n",
    "    # Add arguments\n",
    "    parser.add_argument('--ego_vehicle_extrinsics', type=str, required=False, default='/home/leppsalu/Desktop/Github/CARLA-vehicle-simulation/src/config/carla_extrinsics.urdf',\n",
    "                        help='Path to the ego vehicle extrinsics file')\n",
    "    parser.add_argument('--ego_vehicle_intrinsics', type=str, required=False, default='/home/leppsalu/Desktop/Github/CARLA-vehicle-simulation/src/config/carla_intrinsics.json',\n",
    "                        help='Path to the ego vehicle intrinsics file')\n",
    "    parser.add_argument('--input_dir', type=str, required=False, default='/home/leppsalu/Desktop/Github/CARLA-vehicle-simulation/src/generated_data_town02_discardable_sample',\n",
    "                        help='Path to the input directory')\n",
    "    parser.add_argument('--output_dir', type=str, required=False, default='/home/leppsalu/Desktop/Github/CARLA-vehicle-simulation/src/processed_data_town02_discardable_sample',\n",
    "                        help='Path to the output directory')\n",
    "    parser.add_argument('--n_frames_per_bag', type=int, required=False, default=1800)\n",
    "    # Parse the arguments\n",
    "    args = parser.parse_args()\n",
    "\n",
    "SOURCE_DIR = args.input_dir\n",
    "TARGET_DIR = args.output_dir \n",
    "EXTRINSICS_FILEPATH = args.ego_vehicle_extrinsics\n",
    "INTRINSICS_FILEPATH = args.ego_vehicle_intrinsics\n",
    "N_FRAMES_PER_BAG = args.n_frames_per_bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIDAR_DIR = \"LIDAR_TOP\"\n",
    "CAM_DIRS = [\"CAM_FRONT\", \"CAM_FRONT_LEFT\", \"CAM_FRONT_RIGHT\", \"CAM_BACK\", \"CAM_BACK_LEFT\", \"CAM_BACK_RIGHT\"]\n",
    "SEMANTIC_CAM_DIRS =  [\"SEMANTIC_CAM_FRONT\", \"SEMANTIC_CAM_FRONT_LEFT\", \"SEMANTIC_CAM_FRONT_RIGHT\", \"SEMANTIC_CAM_BACK\", \"SEMANTIC_CAM_BACK_LEFT\", \"SEMANTIC_CAM_BACK_RIGHT\"]\n",
    "DEPTH_CAM_DIRS = [\"DEPTH_CAM_FRONT\", \"DEPTH_CAM_FRONT_LEFT\", \"DEPTH_CAM_FRONT_RIGHT\", \"DEPTH_CAM_BACK\", \"DEPTH_CAM_BACK_LEFT\", \"DEPTH_CAM_BACK_RIGHT\"]\n",
    "DEPTH_BEV_DIR = \"DEPTH_BEV\"\n",
    "DEPTH_VISIBILITY_DIR = \"DEPTH_VISIBILITY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intrinsics file (list of sensor configurations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(INTRINSICS_FILEPATH, \"r\") as INTRINSICS_FILE:\n",
    "    INTRINSICS = json.load(INTRINSICS_FILE)\n",
    "\n",
    "def get_intrinsics_matrix(sensor_name):\n",
    "    if \"DEPTH_\" in sensor_name:\n",
    "        sensor_name = sensor_name.replace(\"DEPTH_\", \"\") # Depth camera and camera intrinsics are the same\n",
    "    if \"SEMANTIC_\" in sensor_name:\n",
    "        sensor_name = sensor_name.replace(\"SEMANTIC_\", \"\") # Semantic camera and camera intrinsics are the same\n",
    "    \n",
    "    camera_intrinsics = INTRINSICS[sensor_name]\n",
    "    fx = camera_intrinsics.get('fx', camera_intrinsics.get('fl'))\n",
    "    fy = camera_intrinsics.get('fy', camera_intrinsics.get('fl'))\n",
    "    w, h = camera_intrinsics.get('w'), camera_intrinsics.get('h')\n",
    "    ppx = w / 2\n",
    "    ppy = h / 2\n",
    "    d_type = camera_intrinsics['disto_type']\n",
    "    D = np.array(camera_intrinsics['disto'])\n",
    "\n",
    "    intrinsics_matrix = np.array([[fx, 0, ppx, 0],\n",
    "                                [0, fy, ppy, 0],\n",
    "                                [0, 0, 1, 0]], dtype=int)\n",
    "    return intrinsics_matrix\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extrinsics (from transforms relsss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post processing constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID_SIZE = 104         # Output grid size = 104x104 pixels\n",
    "GRID_RESOLUTION = 0.5   # Output grid resolution = 0.5x0.5 meters\n",
    "GRID_ORIGIN = np.array([GRID_SIZE // 2, GRID_SIZE // 2]) \n",
    "GRID_DIAGONAL = np.sqrt(GRID_SIZE**2 + GRID_SIZE**2)\n",
    "MAX_POSTPROCESSING_DISTANCE = GRID_RESOLUTION * np.ceil(GRID_DIAGONAL / 2) # Process only points within this distance from origin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filesystem methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_files_in_dir(data_dir, string_to_find):\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if string_to_find in file:\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    os.remove(file_path)\n",
    "                    # print(f\"Removed: {file_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error removing {file_path}: {e}\")\n",
    "\n",
    "def get_all_filenames(dir, no_extension=False):\n",
    "    if no_extension:\n",
    "        return [filename.split(\".\")[0] for filename in os.listdir(dir)]\n",
    "    return [filename for filename in os.listdir(dir)]\n",
    "\n",
    "def clean_up_lidar_dir():\n",
    "    LIDAR_DIR_PATH = os.path.join(SOURCE_DIR, LIDAR_DIR)\n",
    "    remove_files_in_dir(LIDAR_DIR_PATH, \".bev.\")\n",
    "    remove_files_in_dir(LIDAR_DIR_PATH, \".ground.\")\n",
    "\n",
    "def clean_up_camera_dirs():\n",
    "    for CAM_DIR in CAM_DIRS:\n",
    "        CAM_DIR_PATH = os.path.join(SOURCE_DIR, CAM_DIR)\n",
    "        remove_files_in_dir(CAM_DIR_PATH, \".pointcloud.\")\n",
    "        remove_files_in_dir(CAM_DIR_PATH, \".visibility.\")\n",
    "        remove_files_in_dir(CAM_DIR_PATH, \".fov.\")\n",
    "\n",
    "def clean_up_depth_camera_dirs():\n",
    "    for DEPTH_CAM_DIR in DEPTH_CAM_DIRS:\n",
    "        DEPTH_CAM_DIR_PATH = os.path.join(SOURCE_DIR, DEPTH_CAM_DIR)\n",
    "        remove_files_in_dir(DEPTH_CAM_DIR_PATH, \".ply\")\n",
    "        remove_files_in_dir(DEPTH_CAM_DIR_PATH, \".fov.\")\n",
    "        remove_files_in_dir(DEPTH_CAM_DIR_PATH, \".visibility.\")\n",
    "\n",
    "def clean_up_depth_bev_dir():\n",
    "    DEPTH_BEV_DIR_PATH = os.path.join(SOURCE_DIR, DEPTH_BEV_DIR)\n",
    "    remove_files_in_dir(DEPTH_BEV_DIR_PATH, \".\")\n",
    "\n",
    "def clean_up_depth_visibility_dir():\n",
    "    DEPTH_VISIBILITY_DIR_PATH = os.path.join(SOURCE_DIR, DEPTH_VISIBILITY_DIR)\n",
    "    remove_files_in_dir(DEPTH_VISIBILITY_DIR_PATH, \".\")\n",
    "        \n",
    "def save_point_cloud(file_path, point_cloud):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    if type(point_cloud) is o3d.geometry.PointCloud:\n",
    "        o3d.io.write_point_cloud(file_path, point_cloud)\n",
    "        return\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(point_cloud)\n",
    "    o3d.io.write_point_cloud(file_path, pcd)\n",
    "\n",
    "def read_point_cloud(file_path):\n",
    "    point_cloud = o3d.io.read_point_cloud(file_path)\n",
    "    return np.asarray(point_cloud.points)\n",
    "\n",
    "def save_image(file_path, mask):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    cv2.imwrite(file_path, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground Truth from depth camera point clouds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Depth image parsing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_depth_map_from_image(image):\n",
    "    array = image.astype(np.float32)\n",
    "    # Apply (R + G * 256 + B * 256 * 256) / (256 * 256 * 256 - 1).\n",
    "    normalized_depth = np.dot(array[:, :, :3], [65536.0, 256.0, 1.0])\n",
    "    normalized_depth /= 16777215.0  # (256.0 * 256.0 * 256.0 - 1.0)\n",
    "    meters_depth = 1000 * normalized_depth\n",
    "    return meters_depth\n",
    "\n",
    "def clip_depth_map(depth_map, clip_distance):\n",
    "    depth_map[depth_map > clip_distance] = clip_distance\n",
    "    return depth_map\n",
    "\n",
    "def threshold_depth_map(depth_map, max_distance):\n",
    "    depth_map[depth_map > max_distance] = 0.0\n",
    "    return depth_map\n",
    "\n",
    "def create_o3d_pinhole_camera_intrinsics(camera_intrinsics):\n",
    "    height, width = camera_intrinsics[\"h\"], camera_intrinsics[\"w\"]\n",
    "    focal_length = camera_intrinsics[\"fl\"]\n",
    "    def calculate_fov(self, focal_length, image_width):\n",
    "        fov_radians = 2 * np.arctan(image_width / (2 * focal_length))\n",
    "        fov_degrees = np.degrees(fov_radians)\n",
    "        return fov_degrees\n",
    "    fov = calculate_fov(focal_length, width)\n",
    "    fx = fy = 0.5 * width / np.tan(0.5 * np.radians(fov))\n",
    "    cx = width / 2.0\n",
    "    cy = height / 2.0\n",
    "    o3d_intrinsic = o3d.camera.PinholeCameraIntrinsic(width, height, fx, fy, cx, cy)\n",
    "    return o3d_intrinsic\n",
    "\n",
    "def depth_image_to_point_cloud(depth_image, depth_camera_intrinsics, max_distance=None, clip_distance=None):\n",
    "    depth_map = calculate_depth_map_from_image(depth_image)\n",
    "    if clip_distance is not None:\n",
    "        depth_map = clip_depth_map(depth_map, clip_distance)\n",
    "    if max_distance is not None:\n",
    "        depth_map = threshold_depth_map(depth_map, max_distance)\n",
    "    depth_o3d_image = o3d.geometry.Image(depth_map.astype(np.float32))\n",
    "\n",
    "    intrinsics_o3d = create_o3d_pinhole_camera_intrinsics(depth_camera_intrinsics)\n",
    "    \n",
    "    pcd = o3d.geometry.PointCloud.create_from_depth_image(depth_o3d_image, intrinsics_o3d)\n",
    "    points = np.asarray(pcd.points)\n",
    "    points[:, 0] = -points[:, 0]\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    return pcd\n",
    "\n",
    "def create_color_mask(image, colors, inverted=False):\n",
    "    mask = np.full((image.shape[0], image.shape[1]), 0, dtype=np.uint8)\n",
    "    \n",
    "    B, G, R = image[:, :, 0], image[:, :, 1], image[:, :, 2]\n",
    "    # Iterate through the list of colors\n",
    "    for color in colors:\n",
    "        # Extract color channels\n",
    "        r, g, b = color\n",
    "        # Create boolean masks for each channel comparison\n",
    "        r_mask = R == r\n",
    "        g_mask = G == g\n",
    "        b_mask = B == b\n",
    "        # Combine channel masks to get the final color mask\n",
    "        color_mask = r_mask & g_mask & b_mask\n",
    "        # Update the overall mask where any color matches\n",
    "        mask[color_mask] = 255\n",
    "\n",
    "    if inverted:\n",
    "        mask = np.where(mask == 0, 255, 0).astype(np.uint8)\n",
    "        return mask\n",
    "    return mask\n",
    "\n",
    "def mask_image(image, image_mask):\n",
    "    masked_image = np.array(image)\n",
    "    masked_image[~image_mask] = [0,0,0] \n",
    "    return masked_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods for creating FOV masks, visibility masks and BEV maps from depth images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mask(grid, camera_matrix, T, image_size):\n",
    "    homogeneous_grid = np.vstack([grid[i].flatten() for i in range(3)] + [np.ones(grid[0].size)])\n",
    "    tfd_points = np.dot(T, homogeneous_grid)\n",
    "    tfd_points = np.dot(camera_matrix, tfd_points)\n",
    "    mask_z = tfd_points[2] > 0 # Exclude points behind the camera\n",
    "    tfd_points[2][tfd_points[2] == 0] = np.nan  # Replace zeros with NaN to avoid division by zero\n",
    "    projected_points = tfd_points / tfd_points[2]\n",
    "    mask = ((0 <= projected_points[0]) & (projected_points[0] < image_size[0]) &\n",
    "            (0 <= projected_points[1]) & (projected_points[1] < image_size[1]) &\n",
    "            mask_z)\n",
    "    return mask.reshape(grid[0].shape)\n",
    "\n",
    "def get_camera_fov_masks(camera_calibs, lidar_to_cam_tf_list=[], grid_size_m=50, resolution=0.5):\n",
    "    whole_mask = np.zeros((int(grid_size_m), int(grid_size_m)))\n",
    "    x, y = np.meshgrid(np.arange(whole_mask.shape[1]), np.arange(whole_mask.shape[0]))\n",
    "    x = x - whole_mask.shape[1] / 2\n",
    "    y = y - whole_mask.shape[0] / 2\n",
    "    z = np.zeros_like(x)\n",
    "    bev_grid = np.array([x, y, z])\n",
    "    bev_grid = np.expand_dims(bev_grid, axis=-1)\n",
    "\n",
    "    cam_masks = {}\n",
    "\n",
    "    for i, (camera, calib) in enumerate(camera_calibs.items()):\n",
    "        intrinsic = calib['K']\n",
    "\n",
    "        w, h = calib['w'], calib['h']\n",
    "\n",
    "        if lidar_to_cam_tf_list:\n",
    "            cam_T_lidar = np.linalg.inv(lidar_to_cam_tf_list[i])\n",
    "        else:\n",
    "            cam_T_lidar = np.linalg.inv(calib['T'])\n",
    "\n",
    "        mask = generate_mask(bev_grid, camera_matrix=intrinsic, T=cam_T_lidar, image_size=(w, h))\n",
    "        visible_bev = np.array([dim[mask] for dim in bev_grid])\n",
    "\n",
    "        mask_ref = visible_bev[:2]\n",
    "        cam_mask = np.zeros_like(mask)\n",
    "\n",
    "        mask_ref[1] += mask.shape[1] / 2\n",
    "        mask_ref[0] += mask.shape[0] / 2\n",
    "        mask_ref = np.round(mask_ref).astype(int)\n",
    "\n",
    "        cam_mask[mask_ref[1], mask_ref[0]] = 1\n",
    "        cam_mask = cam_mask.squeeze(-1)\n",
    "\n",
    "        cam_masks[camera] = cam_mask\n",
    "    return cam_masks\n",
    "\n",
    "def get_fov_mask(image, transformation_matrix, camera_intrinsics_matrix):\n",
    "    # Example camera calibration data for two cameras\n",
    "    camera_calibs = {\n",
    "        'camera': {\n",
    "            'K': camera_intrinsics_matrix,\n",
    "            'w': image.shape[1],  # Image width\n",
    "            'h': image.shape[0],  # Image height\n",
    "            'T': transformation_matrix\n",
    "        }\n",
    "    }\n",
    "    # Generate the camera FOV masks\n",
    "    cam_masks = get_camera_fov_masks(camera_calibs, grid_size_m=GRID_SIZE, resolution=GRID_RESOLUTION)\n",
    "    fov_mask = np.asarray(cam_masks[\"camera\"], dtype=np.uint8) * 255\n",
    "    \n",
    "    return fov_mask\n",
    "\n",
    "def calculate_fov(focal_length, image_width):\n",
    "    fov_radians = 2 * np.arctan(image_width / (2 * focal_length))\n",
    "    fov_degrees = np.degrees(fov_radians)\n",
    "    return fov_degrees\n",
    "\n",
    "def rasterize_to_bev(points, resolution=0.5, grid_size=25):\n",
    "    bev_map = np.zeros((int(grid_size), int(grid_size)))\n",
    "    # Converting to grid coordinates\n",
    "    grid_coords = np.floor(points[:, :2] / resolution).astype(np.int32) + int(grid_size // 2)\n",
    "    \n",
    "    # Ensure that grid coordinates are within the bounds of the BEV map\n",
    "    valid_points = (grid_coords[:, 0] >= 0) & (grid_coords[:, 0] < bev_map.shape[0]) & \\\n",
    "                   (grid_coords[:, 1] >= 0) & (grid_coords[:, 1] < bev_map.shape[1])\n",
    "    # Populate the BEV map with occupancy\n",
    "    bev_map[grid_coords[valid_points, 1], grid_coords[valid_points, 0]] = 255\n",
    "    return bev_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create point clouds, FOV masks, visibility masks and occupancy maps from depth images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_filenames(dir, no_extension=False):\n",
    "    if no_extension:\n",
    "        return [filename.split(\".\")[0] for filename in os.listdir(dir)]\n",
    "    return [filename for filename in os.listdir(dir)]\n",
    "\n",
    "def get_timestamps_from_filenames(filenames, sorted_order=True):\n",
    "    timestamps_set = {\n",
    "        int(filename.split(\".\")[0]) for filename in filenames if filename.split(\".\")[0].isdigit()\n",
    "    }\n",
    "    timestamps = list(timestamps_set)\n",
    "    if sorted_order:\n",
    "        timestamps = sorted(timestamps)\n",
    "    return timestamps\n",
    "\n",
    "def get_obstacle_point_cloud(depth_image, semantic_image, depth_camera_intrinsics):\n",
    "    semantic_colors = np.asarray(semantic_image)\n",
    "    semantic_tags = semantic_colors[:, :, 2]\n",
    "    semantic_mask = np.isin(\n",
    "        semantic_tags, \n",
    "        [ \n",
    "            SemanticTags.ROADLINE.value, SemanticTags.ROAD.value, \n",
    "            SemanticTags.SIDEWALK.value, SemanticTags.GROUND.value, \n",
    "            SemanticTags.WATER.value, SemanticTags.TERRAIN.value, \n",
    "            SemanticTags.SKY.value\n",
    "        ],\n",
    "        invert=True\n",
    "    )\n",
    "    obstacles_depth_image = mask_image(depth_image, semantic_mask)\n",
    "    obstacles_point_cloud = depth_image_to_point_cloud(obstacles_depth_image, depth_camera_intrinsics, max_distance=MAX_POSTPROCESSING_DISTANCE)\n",
    "    return obstacles_point_cloud\n",
    "\n",
    "def get_ground_point_cloud(depth_image, semantic_image, depth_camera_intrinsics):\n",
    "    semantic_colors = np.asarray(semantic_image)\n",
    "    semantic_tags = semantic_colors[:, :, 2]\n",
    "    semantic_mask = np.isin(\n",
    "        semantic_tags, \n",
    "        [\n",
    "            SemanticTags.ROADLINE.value, SemanticTags.ROAD.value, \n",
    "            SemanticTags.SIDEWALK.value, SemanticTags.GROUND.value, \n",
    "            SemanticTags.WATER.value, SemanticTags.TERRAIN.value\n",
    "        ]\n",
    "    )\n",
    "    ground_depth_image = mask_image(depth_image, semantic_mask)\n",
    "    ground_point_cloud = depth_image_to_point_cloud(ground_depth_image, depth_camera_intrinsics, max_distance=MAX_POSTPROCESSING_DISTANCE)\n",
    "    return ground_point_cloud\n",
    "\n",
    "def get_corrected_point_clouds(obstacles_point_cloud, ground_point_cloud, height_range=(0.2, 1.8)):\n",
    "    def gen_mesh(pcd): \n",
    "        try:\n",
    "            points = np.asarray(pcd.points)\n",
    "        except:\n",
    "            points = pcd\n",
    "        tri = Delaunay(points[:, :2])  # We only use the X and Y coordinates\n",
    "        mesh = o3d.geometry.TriangleMesh()\n",
    "        mesh.vertices = o3d.utility.Vector3dVector(points)\n",
    "        mesh.triangles = o3d.utility.Vector3iVector(tri.simplices)\n",
    "        return mesh\n",
    "    \n",
    "    def mesh_to_cloud_signed_distances(o3d_mesh: o3d.t.geometry.TriangleMesh, cloud: o3d.t.geometry.PointCloud) -> np.ndarray:\n",
    "        scene = o3d.t.geometry.RaycastingScene()\n",
    "        _ = scene.add_triangles(o3d_mesh)\n",
    "        sdf = scene.compute_signed_distance(cloud.point.positions)\n",
    "        return sdf.numpy()\n",
    "\n",
    "    def filter_points_far_from_mesh(pcd, distances, t1, t2):\n",
    "        indices1 = np.where((distances > t1) & (distances <= t2))[0]\n",
    "        indices2 = np.where(distances < t1)[0]\n",
    "        objects = pcd.select_by_index(indices1)\n",
    "        ground = pcd.select_by_index(indices2)\n",
    "        return objects, ground\n",
    "\n",
    "    def remove_points_far_from_mesh(pcd, mesh, height_range=(0.4, 2)):\n",
    "        mesh_t = o3d.t.geometry.TriangleMesh.from_legacy(mesh)\n",
    "        tpcd = o3d.t.geometry.PointCloud.from_legacy(pcd)\n",
    "        sdf = mesh_to_cloud_signed_distances(mesh_t, tpcd)\n",
    "        sdf = np.abs(sdf)\n",
    "        obstacles, ground = filter_points_far_from_mesh(pcd, sdf, *height_range)\n",
    "        return obstacles, ground\n",
    "    try:\n",
    "        ground_mesh = gen_mesh(ground_point_cloud)\n",
    "        obstacles_point_cloud, removed_points = remove_points_far_from_mesh(obstacles_point_cloud, ground_mesh, height_range)\n",
    "        ground_point_cloud += removed_points\n",
    "    except:\n",
    "        pass\n",
    "    return obstacles_point_cloud, ground_point_cloud\n",
    "\n",
    "def get_point_cloud_above_ground(point_cloud, ground_point_cloud):\n",
    "    point_cloud_above_ground, _ = get_corrected_point_clouds(point_cloud, ground_point_cloud, height_range=(0.0, 0.1))\n",
    "    return point_cloud_above_ground\n",
    "\n",
    "def get_visible_voxels_point_cloud(obstacles_point_cloud, cameras):\n",
    "    voxel_grid_dims = (GRID_SIZE, GRID_SIZE, GRID_SIZE)\n",
    "    voxel_size = GRID_RESOLUTION\n",
    "    occupied_voxel_centroids = obstacles_point_cloud.voxel_down_sample(voxel_size).points\n",
    "    viewshed = ViewShed3D(occupied_voxel_centroids, voxel_size, voxel_grid_dims)\n",
    "\n",
    "    visible_voxels = []\n",
    "    for camera in cameras:\n",
    "        camera_matrix = camera.get_projection_matrix()\n",
    "        camera_image_width = camera.get_image_width()\n",
    "        camera_image_height = camera.get_image_height()\n",
    "        voxels = viewshed.compute_visible_voxels(camera_matrix, camera_image_width, camera_image_height)\n",
    "        visible_voxels.append(voxels)\n",
    "    visible_voxels = np.array(np.concatenate(visible_voxels))\n",
    "\n",
    "    visible_voxels_point_cloud = o3d.geometry.PointCloud()\n",
    "    visible_voxels_point_cloud.points = o3d.utility.Vector3dVector(visible_voxels)\n",
    "    return visible_voxels_point_cloud\n",
    "\n",
    "clean_up_lidar_dir()\n",
    "clean_up_depth_camera_dirs()\n",
    "clean_up_depth_bev_dir()\n",
    "clean_up_depth_visibility_dir()\n",
    "\n",
    "all_filenames = get_all_filenames(os.path.join(SOURCE_DIR, DEPTH_CAM_DIRS[0]))\n",
    "timestamps = get_timestamps_from_filenames(all_filenames)\n",
    "\n",
    "print(f\"Post-processing simulation data ...\")\n",
    "for i, timestamp in enumerate(timestamps):\n",
    "    cumulative_obstacle_points = []\n",
    "    cumulative_ground_points = []\n",
    "    \n",
    "    for (SEM_DIR, DEPTH_DIR, CAM_DIR) in zip(SEMANTIC_CAM_DIRS, DEPTH_CAM_DIRS, CAM_DIRS):\n",
    "        depth_camera_transform_path = os.path.join(SOURCE_DIR, DEPTH_DIR, f\"{timestamp}.npy\")\n",
    "        depth_camera_transform = np.load(depth_camera_transform_path)\n",
    "        depth_image_path = os.path.join(SOURCE_DIR, DEPTH_DIR, f\"{timestamp}.png\")\n",
    "        depth_image = cv2.imread(depth_image_path)\n",
    "        depth_camera_instrinsics = INTRINSICS_MATRICES[CAM_DIR]\n",
    "                \n",
    "        semantic_image_path = os.path.join(SOURCE_DIR, SEM_DIR, f\"{timestamp}.png\")\n",
    "        semantic_image = cv2.imread(semantic_image_path)\n",
    "\n",
    "        ground_point_cloud = get_ground_point_cloud(depth_image, semantic_image, depth_camera_instrinsics)\n",
    "        ground_point_cloud.transform(depth_camera_transform)\n",
    "        cumulative_ground_points.append(ground_point_cloud.points)\n",
    "\n",
    "        obstacle_point_cloud = get_obstacle_point_cloud(depth_image, semantic_image, depth_camera_instrinsics)\n",
    "        obstacle_point_cloud.transform(depth_camera_transform)\n",
    "        cumulative_obstacle_points.append(obstacle_point_cloud.points)\n",
    "\n",
    "    cumulative_ground_point_cloud = o3d.geometry.PointCloud()\n",
    "    cumulative_ground_point_cloud.points = o3d.utility.Vector3dVector(np.concatenate(cumulative_ground_points))\n",
    "    cumulative_ground_point_cloud = cumulative_ground_point_cloud.voxel_down_sample(GRID_RESOLUTION)\n",
    "    cumulative_obstacle_point_cloud = o3d.geometry.PointCloud()\n",
    "    cumulative_obstacle_point_cloud.points = o3d.utility.Vector3dVector(np.concatenate(cumulative_obstacle_points))\n",
    "    cumulative_obstacle_point_cloud, cumulative_ground_point_cloud = get_corrected_point_clouds(cumulative_obstacle_point_cloud, cumulative_ground_point_cloud)\n",
    "\n",
    "    lidar_transform = np.load(os.path.join(SOURCE_DIR, LIDAR_DIR, f\"{timestamp}.npy\"))\n",
    "\n",
    "    cumulative_obstacle_point_cloud.transform(np.linalg.inv(lidar_transform))\n",
    "    obstacles_point_cloud_file_path = os.path.join(SOURCE_DIR, DEPTH_BEV_DIR, f\"{timestamp}.obstacles.ply\")\n",
    "    save_point_cloud(obstacles_point_cloud_file_path, cumulative_obstacle_point_cloud)\n",
    "    # print(f\"Added: {obstacles_point_cloud_file_path}\")\n",
    "    cumulative_ground_point_cloud.transform(np.linalg.inv(lidar_transform))\n",
    "    ground_point_cloud_file_path = os.path.join(SOURCE_DIR, DEPTH_BEV_DIR, f\"{timestamp}.ground.ply\")\n",
    "    save_point_cloud(ground_point_cloud_file_path, cumulative_ground_point_cloud)\n",
    "    # print(f\"Added: {ground_point_cloud_file_path}\")\n",
    "    occupancy_image = rasterize_to_bev(np.asarray(cumulative_obstacle_point_cloud.points), resolution=GRID_RESOLUTION, grid_size=GRID_SIZE)\n",
    "    occupancy_image_path = os.path.join(SOURCE_DIR, DEPTH_BEV_DIR, f\"{timestamp}.bev.png\")\n",
    "    save_image(occupancy_image_path, occupancy_image)\n",
    "    # print(f\"Added: {occupancy_image_path}\")\n",
    "\n",
    "    def get_signed_distance_field_from_occupancy_image(occupancy_image):\n",
    "        img = np.array(occupancy_image)\n",
    "        inv_arr = (255 - np.array(img))\n",
    "        sdf = distance_transform_edt(inv_arr).astype(np.float32)\n",
    "        sdf += 1\n",
    "        sdf = 1 / sdf \n",
    "        return sdf\n",
    "    \n",
    "    def get_sdf_as_image(sdf_array):\n",
    "        sdf_array = (sdf_array / sdf_array.max() * 255).astype(np.uint8)\n",
    "        sdf_image = cv2.applyColorMap(sdf_array, cv2.COLORMAP_JET)\n",
    "        return sdf_image\n",
    "    \n",
    "    sdf = get_signed_distance_field_from_occupancy_image(occupancy_image)\n",
    "    sdf_path = os.path.join(SOURCE_DIR, DEPTH_BEV_DIR, f\"{timestamp}.sdf.npy\")\n",
    "    np.save(sdf_path, sdf)\n",
    "    # print(f\"Added: {sdf_path}\")\n",
    "    sdf_image = get_sdf_as_image(sdf)\n",
    "    sdf_image_path = os.path.join(SOURCE_DIR, DEPTH_BEV_DIR, f\"{timestamp}.sdf.png\")\n",
    "    save_image(sdf_image_path, sdf_image)\n",
    "    # print(f\"Added: {sdf_image_path}\")\n",
    "    transform_file_path = os.path.join(SOURCE_DIR, DEPTH_BEV_DIR, f\"{timestamp}.npy\")\n",
    "    np.save(transform_file_path, lidar_transform)\n",
    "    # print(f\"Added: {transform_file_path}\")\n",
    "\n",
    "    visible_voxel_point_cloud = get_visible_voxels_point_cloud(cumulative_obstacle_point_cloud)\n",
    "    cumulative_visibility_mask = rasterize_to_bev(np.asarray(visible_voxel_point_cloud.points), resolution=GRID_RESOLUTION, grid_size=GRID_SIZE)\n",
    "    cumulative_visibility_mask[occupancy_image > 0] = 0\n",
    "    cumulative_visibility_mask_path = os.path.join(SOURCE_DIR, DEPTH_VISIBILITY_DIR, f\"{timestamp}.png\")\n",
    "    save_image(cumulative_visibility_mask_path, cumulative_visibility_mask)\n",
    "    # print(f\"Added: {cumulative_visibility_mask_path}\")\n",
    "\n",
    "    transform_file_path = os.path.join(SOURCE_DIR, DEPTH_VISIBILITY_DIR, f\"{timestamp}.npy\")\n",
    "    np.save(transform_file_path, lidar_transform)\n",
    "    # print(f\"Added: {transform_file_path}\")\n",
    "\n",
    "    for CAM_DIR, DEPTH_DIR in zip(CAM_DIRS, DEPTH_CAM_DIRS):\n",
    "        depth_image_path = os.path.join(SOURCE_DIR, DEPTH_DIR, f\"{timestamp}.png\")\n",
    "        depth_image = cv2.imread(depth_image_path)\n",
    "        \n",
    "        depth_camera_transform_path = os.path.join(SOURCE_DIR, DEPTH_DIR, f\"{timestamp}.npy\")\n",
    "        depth_camera_transform = np.load(depth_camera_transform_path)\n",
    "        \n",
    "        lidar_transform_path = os.path.join(SOURCE_DIR, LIDAR_DIR, f\"{timestamp}.npy\")\n",
    "        lidar_transform = np.load(lidar_transform_path)\n",
    "        lidar_transform_inv = np.linalg.inv(lidar_transform)\n",
    "        combined_transform = np.dot(lidar_transform_inv, depth_camera_transform)\n",
    "        \n",
    "        intrinsics_matrix = get_intrinsics_matrix(DEPTH_DIR)\n",
    "        camera_fov_mask = get_fov_mask(depth_image, combined_transform, intrinsics_matrix)\n",
    "        fov_mask_path = os.path.join(SOURCE_DIR, DEPTH_DIR, f\"{timestamp}.fov.png\")\n",
    "        save_image(fov_mask_path, camera_fov_mask)\n",
    "        # print(f\"Added: {fov_mask_path}\")\n",
    "\n",
    "        camera_visibility_mask = np.array((cumulative_visibility_mask > 0) & (camera_fov_mask > 0), dtype=np.uint8) * 255\n",
    "        visibility_mask_path = os.path.join(SOURCE_DIR, DEPTH_DIR, f\"{timestamp}.visibility.png\")\n",
    "        save_image(visibility_mask_path, camera_visibility_mask)\n",
    "        # print(f\"Added: {visibility_mask_path}\")\n",
    "\n",
    "    def get_lidar_obstacle_point_cloud(semantic_point_cloud):\n",
    "        # Extract colors from the point cloud\n",
    "        semantic_colors = np.asarray(semantic_point_cloud.colors)\n",
    "        r_channel = semantic_colors[:, 0] * 255\n",
    "        mask = np.isin(\n",
    "            r_channel, \n",
    "            [ \n",
    "                SemanticTags.ROADLINE.value, SemanticTags.ROAD.value, SemanticTags.SIDEWALK.value,\n",
    "                SemanticTags.GROUND.value, SemanticTags.WATER.value, SemanticTags.TERRAIN.value, \n",
    "                SemanticTags.SKY.value\n",
    "            ],\n",
    "            invert=True\n",
    "        )\n",
    "        # Filter the points and colors based on the mask\n",
    "        filtered_points = np.asarray(semantic_point_cloud.points)[mask]\n",
    "        filtered_colors = semantic_colors[mask]\n",
    "        # Create a new point cloud with the filtered points and colors\n",
    "        filtered_point_cloud = o3d.geometry.PointCloud()\n",
    "        filtered_point_cloud.points = o3d.utility.Vector3dVector(filtered_points)\n",
    "        filtered_point_cloud.colors = o3d.utility.Vector3dVector(filtered_colors)\n",
    "        return filtered_point_cloud\n",
    "    \n",
    "    def get_lidar_ground_point_cloud(semantic_point_cloud):\n",
    "        # Extract colors from the point cloud\n",
    "        semantic_colors = np.asarray(semantic_point_cloud.colors)\n",
    "        r_channel = semantic_colors[:, 0] * 255\n",
    "        mask = np.isin(\n",
    "            r_channel, \n",
    "            [\n",
    "                SemanticTags.ROADLINE.value, SemanticTags.ROAD.value, \n",
    "                SemanticTags.SIDEWALK.value, SemanticTags.GROUND.value, \n",
    "                SemanticTags.WATER.value, SemanticTags.TERRAIN.value,\n",
    "                SemanticTags.UNLABELED.value # Unlabeled points are considered ground because CARLA considers UE4 landscapes as UNLABELED\n",
    "            ]\n",
    "        )\n",
    "        # Filter the points and colors based on the mask\n",
    "        filtered_points = np.asarray(semantic_point_cloud.points)[mask]\n",
    "        filtered_colors = semantic_colors[mask]\n",
    "        # Create a new point cloud with the filtered points and colors\n",
    "        filtered_point_cloud = o3d.geometry.PointCloud()\n",
    "        filtered_point_cloud.points = o3d.utility.Vector3dVector(filtered_points)\n",
    "        filtered_point_cloud.colors = o3d.utility.Vector3dVector(filtered_colors)\n",
    "        return filtered_point_cloud\n",
    "    \n",
    "    \n",
    "    lidar_point_cloud_path = os.path.join(SOURCE_DIR, LIDAR_DIR, f\"{timestamp}.ply\")\n",
    "    lidar_point_cloud = o3d.io.read_point_cloud(lidar_point_cloud_path)\n",
    "    lidar_point_cloud = lidar_point_cloud.transform(np.array([\n",
    "        [0, -1, 0, 0],\n",
    "        [1,  0, 0, 0],\n",
    "        [0,  0, 1, 0],\n",
    "        [0,  0, 0, 1]\n",
    "    ]))\n",
    "    lidar_ground_point_cloud = get_lidar_ground_point_cloud(lidar_point_cloud)\n",
    "    lidar_ground_point_cloud_path = os.path.join(SOURCE_DIR, LIDAR_DIR, f\"{timestamp}.ground.ply\")\n",
    "    save_point_cloud(lidar_ground_point_cloud_path, lidar_ground_point_cloud)\n",
    "    # print(f\"Added: {lidar_ground_point_cloud_path}\")\n",
    "    lidar_obstacle_point_cloud = get_lidar_obstacle_point_cloud(lidar_point_cloud)\n",
    "    lidar_obstacle_point_cloud, lidar_ground_point_cloud = get_corrected_point_clouds(lidar_obstacle_point_cloud, lidar_ground_point_cloud)\n",
    "    lidar_obstacle_point_cloud_path = os.path.join(SOURCE_DIR, LIDAR_DIR, f\"{timestamp}.obstacles.ply\")\n",
    "    save_point_cloud(lidar_obstacle_point_cloud_path, lidar_obstacle_point_cloud)\n",
    "\n",
    "    lidar_bev_image = rasterize_to_bev(np.asarray(lidar_obstacle_point_cloud.points), resolution=GRID_RESOLUTION, grid_size=GRID_SIZE)\n",
    "    lidar_bev_image_path = os.path.join(SOURCE_DIR, LIDAR_DIR, f\"{timestamp}.bev.png\")\n",
    "    save_image(lidar_bev_image_path, lidar_bev_image)\n",
    "    # print(f\"Added: {lidar_bev_image_path}\")\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f\"{datetime.now()} Processed {((i+1) / len(timestamps) * 100):.6f}% of frames in the dataset\")\n",
    "print(f\"{datetime.now()} Processed {((i+1) / len(timestamps) * 100):.6f}% of frames in the dataset\")\n",
    "print(f\"Processed data in {SOURCE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export processed files to target directory (in suitable directory tree format for machine learning pipeline) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_CAM_DIRS = [\"CAM_FRONT\", \"CAM_FRONT_LEFT\", \"CAM_FRONT_RIGHT\", \"CAM_BACK\", \"CAM_BACK_LEFT\", \"CAM_BACK_RIGHT\"]\n",
    "TARGET_LIDAR_DIR = \"LIDAR_TOP\"\n",
    "TARGET_FOV_MASKS_DIR = \"fov_masks\"\n",
    "TARGET_BEVS_DIR = \"bevs\"\n",
    "TARGET_SDFS_DIR = \"sdfs\"\n",
    "TARGET_VISIBILITY_MASKS_DIR = \"visibility_masks\"\n",
    "TARGET_CUMULATIVE_MASKS_DIR = \"cumulative_masks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_target_dir():\n",
    "    if not os.path.exists(TARGET_DIR):\n",
    "        return\n",
    "    for subdir in os.listdir(TARGET_DIR):\n",
    "        shutil.rmtree(os.path.join(TARGET_DIR, subdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_file_to_target_dir(source_file_path, target_file_path):\n",
    "    target_directory_path = os.path.dirname(target_file_path)\n",
    "    os.makedirs(target_directory_path, exist_ok=True)\n",
    "    shutil.copyfile(source_file_path, target_file_path)\n",
    "\n",
    "clean_up_target_dir()\n",
    "\n",
    "all_timestamps = get_all_filenames(os.path.join(SOURCE_DIR, DEPTH_CAM_DIRS[0]), no_extension=True)\n",
    "unique_timestamps = set(all_timestamps)\n",
    "sorted_timestamps = sorted(unique_timestamps, key=int)\n",
    "\n",
    "print(f\"Exporting post-processed data...\")\n",
    "for i, timestamp in enumerate(sorted_timestamps):\n",
    "    if (i % N_FRAMES_PER_BAG) == 0:\n",
    "        start_timestamp = sorted_timestamps[i]\n",
    "        end_timestamp = sorted_timestamps[-1] if (i+N_FRAMES_PER_BAG-1) >= len(sorted_timestamps) else sorted_timestamps[i+N_FRAMES_PER_BAG-1]\n",
    "        TARGET_DIRNAME = os.path.basename(TARGET_DIR)\n",
    "        TARGET_BAG_DIR = f\"{TARGET_DIRNAME}_frames_{start_timestamp}_{end_timestamp}\"\n",
    "    \n",
    "    for CAM_DIR in CAM_DIRS:\n",
    "        source_file_path = os.path.join(SOURCE_DIR, CAM_DIR, f\"{timestamp}.png\")\n",
    "        target_file_path = os.path.join(TARGET_DIR, TARGET_BAG_DIR, CAM_DIR, f\"{timestamp}.png\")\n",
    "        copy_file_to_target_dir(source_file_path, target_file_path)\n",
    "        source_file_path = os.path.join(SOURCE_DIR, CAM_DIR, f\"{timestamp}.npy\")\n",
    "        target_file_path = os.path.join(TARGET_DIR, TARGET_BAG_DIR, CAM_DIR, f\"{timestamp}.npy\")\n",
    "        copy_file_to_target_dir(source_file_path, target_file_path)\n",
    "\n",
    "    source_file_path = os.path.join(SOURCE_DIR, LIDAR_DIR, f\"{timestamp}.ply\")\n",
    "    target_file_path = os.path.join(TARGET_DIR, TARGET_BAG_DIR, LIDAR_DIR, f\"{timestamp}.ply\")\n",
    "    copy_file_to_target_dir(source_file_path, target_file_path)\n",
    "    source_file_path = os.path.join(SOURCE_DIR, LIDAR_DIR, f\"{timestamp}.npy\")\n",
    "    target_file_path = os.path.join(TARGET_DIR, TARGET_BAG_DIR, LIDAR_DIR, f\"{timestamp}.npy\")\n",
    "    copy_file_to_target_dir(source_file_path, target_file_path)\n",
    "\n",
    "    for CAM_DIR, DEPTH_CAM_DIR in zip(CAM_DIRS, DEPTH_CAM_DIRS):\n",
    "        source_file_path = os.path.join(SOURCE_DIR, DEPTH_CAM_DIR, f\"{timestamp}.fov.png\")\n",
    "        target_file_path = os.path.join(TARGET_DIR, TARGET_BAG_DIR, TARGET_FOV_MASKS_DIR, CAM_DIR, f\"{timestamp}.png\")\n",
    "        copy_file_to_target_dir(source_file_path, target_file_path)\n",
    "        source_file_path = os.path.join(SOURCE_DIR, DEPTH_CAM_DIR, f\"{timestamp}.npy\")\n",
    "        target_file_path = os.path.join(TARGET_DIR, TARGET_BAG_DIR, TARGET_FOV_MASKS_DIR, CAM_DIR, f\"{timestamp}.npy\")\n",
    "        copy_file_to_target_dir(source_file_path, target_file_path)\n",
    "\n",
    "        source_file_path = os.path.join(SOURCE_DIR, DEPTH_CAM_DIR, f\"{timestamp}.visibility.png\")\n",
    "        target_file_path = os.path.join(TARGET_DIR, TARGET_BAG_DIR, TARGET_VISIBILITY_MASKS_DIR, CAM_DIR, f\"{timestamp}.png\")\n",
    "        copy_file_to_target_dir(source_file_path, target_file_path)\n",
    "        source_file_path = os.path.join(SOURCE_DIR, DEPTH_CAM_DIR, f\"{timestamp}.npy\")\n",
    "        target_file_path = os.path.join(TARGET_DIR, TARGET_BAG_DIR, TARGET_VISIBILITY_MASKS_DIR, CAM_DIR, f\"{timestamp}.npy\")\n",
    "        copy_file_to_target_dir(source_file_path, target_file_path)\n",
    "\n",
    "    source_file_path = os.path.join(SOURCE_DIR, DEPTH_BEV_DIR, f\"{timestamp}.bev.png\")\n",
    "    target_file_path = os.path.join(TARGET_DIR, TARGET_BAG_DIR, TARGET_BEVS_DIR, f\"{timestamp}.png\")\n",
    "    copy_file_to_target_dir(source_file_path, target_file_path)\n",
    "\n",
    "    source_file_path = os.path.join(SOURCE_DIR, DEPTH_BEV_DIR, f\"{timestamp}.sdf.npy\")\n",
    "    target_file_path = os.path.join(TARGET_DIR, TARGET_BAG_DIR, TARGET_SDFS_DIR, f\"{timestamp}.npy\")\n",
    "    copy_file_to_target_dir(source_file_path, target_file_path)\n",
    "    source_file_path = os.path.join(SOURCE_DIR, DEPTH_BEV_DIR, f\"{timestamp}.sdf.png\")\n",
    "    target_file_path = os.path.join(TARGET_DIR, TARGET_BAG_DIR, TARGET_SDFS_DIR, f\"{timestamp}.png\")\n",
    "    copy_file_to_target_dir(source_file_path, target_file_path)\n",
    "\n",
    "    source_file_path = os.path.join(SOURCE_DIR, DEPTH_VISIBILITY_DIR, f\"{timestamp}.png\")\n",
    "    target_file_path = os.path.join(TARGET_DIR, TARGET_BAG_DIR, TARGET_VISIBILITY_MASKS_DIR, TARGET_CUMULATIVE_MASKS_DIR, f\"{timestamp}.png\")\n",
    "    copy_file_to_target_dir(source_file_path, target_file_path)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Exported {((i+1) / len(unique_timestamps) * 100):.6f}% of frames in the dataset\")\n",
    "\n",
    "print(f\"Exported {((i+1) / len(unique_timestamps) * 100):.6f}% of frames in the dataset\")\n",
    "print(f\"Exported post-processed data to {TARGET_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Post-processing completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
